{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "2db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import calendar\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "security_id = \"500325\"\n",
    "name = \"RELIANCE INDUSTRIES LTD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()"
   ]
  },
  {
   "source": [
    "# Reading the data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_df = pd.read_csv(os.path.join(path,\"Data/Index.csv\"))\n",
    "corporate_df = pd.read_csv(os.path.join(path,\"Data/CorporateActions/\"+security_id+\".csv\"))\n",
    "revenue_df = pd.read_csv(os.path.join(path,\"Data/Revenue/\"+security_id+\".csv\"))\n",
    "stock_df = pd.read_csv(os.path.join(path,\"Data/Stock/\"+security_id+\".csv\"))"
   ]
  },
  {
   "source": [
    "# Data Cleaning"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_duplicate_rows(df):\n",
    "    df = df.drop_duplicates(subset=[\"Date\"],keep=\"first\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_with_previous_values(df):\n",
    "    df.fillna(method=\"ffill\",inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_missing_rows(df,ind):\n",
    "    df.Date = pd.to_datetime(df.Date)\n",
    "    ind.Date = pd.to_datetime(ind.Date)\n",
    "    s = df.Date.head(1).values[0]\n",
    "    e = df.Date.tail(1).values[0]\n",
    "    ind = ind[ind.Date.between(e,s)]\n",
    "    missing_df = pd.DataFrame(columns=df.columns)\n",
    "    indexes_dates = ind.Date.values\n",
    "    df.Date = pd.to_datetime(df.Date)\n",
    "    df_dates = df.Date.values\n",
    "    start = 0\n",
    "    for i,v in enumerate(indexes_dates):\n",
    "        if v not in df.Date.values:\n",
    "            res = list(np.append(ind.iloc[i].values,[np.nan]*8))\n",
    "            missing_df.loc[start] = res\n",
    "            start += 1\n",
    "    df = pd.concat([df,missing_df])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(df,ind):\n",
    "    df = drop_duplicate_rows(df)\n",
    "    ind = drop_duplicate_rows(ind)\n",
    "    df = add_missing_rows(df,ind)\n",
    "    df = fill_with_previous_values(df)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock_df = cleaning(stock_df,index_df)"
   ]
  },
  {
   "source": [
    "# Applying Corporate Actions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bonus_issue(stock,start_date,end_date,r1,r2):\n",
    "    specific_dates = stock[stock.Date.between(end_date,start_date)]\n",
    "    for index,row in specific_dates.iterrows():\n",
    "        specific_dates.loc[index,\"Open Price\"] = specific_dates.loc[index,\"Open Price\"] * (r2/(r1+r2))\n",
    "        specific_dates.loc[index,\"Low Price\"] = specific_dates.loc[index,\"Low Price\"] * (r2/(r1+r2))\n",
    "        specific_dates.loc[index,\"High Price\"] = specific_dates.loc[index,\"High Price\"] * (r2/(r1+r2))\n",
    "        specific_dates.loc[index,\"Close Price\"] = specific_dates.loc[index,\"Close Price\"] * (r2/(r1+r2))\n",
    "        specific_dates.loc[index,\"WAP\"] = specific_dates.loc[index,\"WAP\"] * (r2/(r1+r2))\n",
    "        stock.loc[index] = specific_dates.loc[index]\n",
    "    return stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stock_split(stock,start_date,end_date,r1,r2):\n",
    "    specific_dates = stock[stock.Date.between(end_date,start_date)]\n",
    "    for index,row in specific_dates.iterrows():\n",
    "        specific_dates.loc[index,\"Open Price\"] = specific_dates.loc[index,\"Open Price\"] * (r1/r2)\n",
    "        specific_dates.loc[index,\"Low Price\"] = specific_dates.loc[index,\"Low Price\"] * (r1/r2)\n",
    "        specific_dates.loc[index,\"High Price\"] = specific_dates.loc[index,\"High Price\"] * (r1/r2)\n",
    "        specific_dates.loc[index,\"Close Price\"] = specific_dates.loc[index,\"Close Price\"] * (r1/r2)\n",
    "        specific_dates.loc[index,\"WAP\"] = specific_dates.loc[index,\"WAP\"] * (r1/r2)\n",
    "        stock.loc[index] = specific_dates.loc[index]\n",
    "    return stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dividend(stock,corporate):\n",
    "    corporate['Ex Date'] = pd.to_datetime(corporate['Ex Date'], errors='coerce')\n",
    "    stock['Date'] = pd.to_datetime(stock['Date'], errors='coerce')\n",
    "\n",
    "    dividend = corporate[corporate['Purpose'].str.contains(\"Dividend\")]\n",
    "    result = {}\n",
    "    for index,row in dividend.iterrows():\n",
    "        year = row[\"Ex Date\"].year\n",
    "        month = row[\"Ex Date\"].month\n",
    "        amount = re.findall(r\"\\d+.?\\d*\",row[\"Purpose\"])[0]\n",
    "        res = result.get(year,{})\n",
    "        q = \"1q\" if 1 <= month <= 3 else \"2q\" if 4 <= month <= 6 else \"3q\" if 6 <= month <= 9 else \"4q\"\n",
    "        val = res.get(q,[])\n",
    "        val.append(float(amount))\n",
    "        res[q] = val\n",
    "        result[year] = res\n",
    "    for year,quaters in result.items():\n",
    "        for q, a in quaters.items():\n",
    "            quaters[q] = sum(a)/len(a)\n",
    "        result[year] = quaters\n",
    "    divList = list()\n",
    "    for index,row in stock.iterrows():\n",
    "        year = row[\"Date\"].year\n",
    "        month = row[\"Date\"].month\n",
    "        q = \"1q\" if 1 <= month <= 3 else \"2q\" if 4 <= month <= 6 else \"3q\" if 6 <= month <= 9 else \"4q\"\n",
    "        if result.get(year) != None:\n",
    "            if result.get(year).get(q) != None:\n",
    "                divList.append(result.get(year).get(q))\n",
    "            else:\n",
    "                divList.append(0)\n",
    "        else:\n",
    "            divList.append(0)\n",
    "    stock[\"Dividend Value\"] = divList\n",
    "    return stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_corporate_actions(stock,corporate):\n",
    "    stock[\"Date\"] = pd.to_datetime(stock[\"Date\"])\n",
    "    corporate[\"Ex Date\"] = pd.to_datetime(corporate[\"Ex Date\"],errors='coerce')\n",
    "    # corporate[\"BC Start Date\"] = pd.to_datetime(corporate[\"BC Start Date\"],errors='coerce')\n",
    "    # corporate[\" BC End Date\\t\"] = pd.to_datetime(corporate[\" BC End Date\\t\"],errors='coerce')\n",
    "    # corporate[\"ND Start Date\"] = pd.to_datetime(corporate[\"ND Start Date\"],errors='coerce')\n",
    "    # corporate[\"ND End Date\"] = pd.to_datetime(corporate[\"ND End Date\"],errors='coerce')\n",
    "    \n",
    "    bonus_df = corporate[corporate['Purpose'].str.contains(\"Bonus\")]\n",
    "    for index,row in bonus_df.iterrows():\n",
    "        start_date = bonus_df.loc[index,\"Ex Date\"]\n",
    "        ratio = bonus_df.loc[index,\"Purpose\"]\n",
    "        r1,r2 = re.findall(r\"\\d+\",ratio)\n",
    "        r1,r2 = int(r1),int(r2)\n",
    "        end_date = stock.tail(1)[\"Date\"].values[0]\n",
    "        stock = bonus_issue(stock,start_date,end_date,r1,r2)\n",
    "\n",
    "    stock_split_df = corporate[corporate['Purpose'].str.contains(\"Stock\")]\n",
    "    for index,row in stock_split_df.iterrows():\n",
    "        start_date = stock_split_df.loc[index,\"Ex Date\"]\n",
    "        ratio = stock_split_df.loc[index,\"Purpose\"]\n",
    "        r1,r2 = re.findall(r\"\\d+\",ratio)\n",
    "        r1,r2 = int(r1),int(r2)\n",
    "        end_date = stock.tail(1)[\"Date\"].values[0]\n",
    "        stock = stock_split(stock,start_date,end_date,r1,r2)\n",
    "    \n",
    "    stock = create_dividend(stock,corporate)\n",
    "\n",
    "    return stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock_df = apply_corporate_actions(stock_df,corporate_df)"
   ]
  },
  {
   "source": [
    "# Create New Index "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_index():\n",
    "    ind = pd.read_csv(os.path.join(path,\"Data/Index.csv\"))\n",
    "    ind[\"% Return\"] = ((ind[\"Close\"] / ind['Close'].shift(1))-1)*100\n",
    "    ind[\"% YTD\"] = ((ind.tail(1)['Close'].values[0]/ind[\"Close\"])-1)*100\n",
    "    ind.to_csv(os.path.join(path,\"Data/modIndex.csv\"),index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_index()"
   ]
  },
  {
   "source": [
    "# Create Beta Feature"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_beta(stock):\n",
    "    stock[\"% Return of Company\"] = ((stock[\"Close Price\"] / stock['Close Price'].shift(1))-1)*100\n",
    "    ind = pd.read_csv(os.path.join(path,\"Data/modIndex.csv\"))\n",
    "    ind[\"Date\"] = pd.to_datetime(ind[\"Date\"])\n",
    "    s = stock.Date.head(1).values[0]\n",
    "    e = stock.Date.tail(1).values[0]\n",
    "    ind = ind[ind.Date.between(e,s)]\n",
    "    ind.rename(columns={'Close':'Close Price of SP500', '% Return':'% Return of SP500'}, inplace=True)\n",
    "    ind.drop(['Open', 'High', 'Low', '% YTD'], axis = 1,inplace=True) \n",
    "    ind[\"Date\"] = pd.to_datetime(ind[\"Date\"])\n",
    "    stock[\"Date\"] = pd.to_datetime(stock[\"Date\"])\n",
    "    stock = pd.merge(stock, ind, on=\"Date\", how = \"left\")\n",
    "\n",
    "    sp500 = stock[\"% Return of SP500\"]\n",
    "    company = stock[\"% Return of Company\"]\n",
    "    results = list()\n",
    "    for i in range(stock.shape[0]):\n",
    "        # cov = np.cov(company[i:],sp500[i:])[0][1]\n",
    "        cov = np.ma.cov(np.ma.masked_invalid(np.array(company[i:],sp500[i:])),rowvar=False)\n",
    "        var = np.nanvar(sp500[i:])\n",
    "        res = var/cov\n",
    "        results.append(res)\n",
    "    stock[\"Beta\"] = results\n",
    "    return stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock_df = calculate_beta(stock_df)"
   ]
  },
  {
   "source": [
    "# Create Risk Free Rate Feature"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_risk_free_column(stock):\n",
    "    riskrates = pd.read_csv(os.path.join(path,\"Data/RiskFreeRate.csv\"))\n",
    "    riskrates[\"Date\"] = pd.to_datetime(riskrates[\"Date\"])\n",
    "    stock[\"Date\"] = pd.to_datetime(stock[\"Date\"])\n",
    "    riskrates[\"Rate\"] = pd.to_numeric(riskrates[\"Rate\"])\n",
    "    res = pd.merge(stock, riskrates, on=\"Date\", how = \"left\")\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock_df = add_risk_free_column(stock_df)"
   ]
  },
  {
   "source": [
    "# Create Alpha Feature"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_alpha(stock):\n",
    "    stock[\"% YTD of Company\"] = ((stock.tail(1)['Close Price'].values[0]/stock[\"Close Price\"])-1)*100\n",
    "    ind = pd.read_csv(os.path.join(path,\"Data/modIndex.csv\"))\n",
    "    ind[\"Date\"] = pd.to_datetime(ind[\"Date\"])\n",
    "    s = stock.Date.head(1).values[0]\n",
    "    e = stock.Date.tail(1).values[0]\n",
    "    ind = ind[ind.Date.between(e,s)]\n",
    "    ind.drop(['Open', 'High', 'Low', \"Close\", \"% Return\"], axis = 1,inplace=True) \n",
    "    ind.rename(columns={'% YTD':'% YTD of SP500'}, inplace=True)\n",
    "    ind[\"Date\"] = pd.to_datetime(ind[\"Date\"])\n",
    "    stock[\"Date\"] = pd.to_datetime(stock[\"Date\"])\n",
    "    stock = pd.merge(stock, ind, on=\"Date\", how = \"left\")\n",
    "    stock[\"Beta\"] = pd.to_numeric(stock[\"Beta\"],errors='coerce')\n",
    "    stock[\"Alpha\"] = stock[\"% YTD of Company\"]-(stock[\"Rate\"]+(stock[\"Beta\"]*(stock[\"% YTD of SP500\"] - stock[\"Rate\"])))\n",
    "    return stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock_df = calculate_alpha(stock_df)"
   ]
  },
  {
   "source": [
    "# Create Lower Band, Upper Band, Band Area Features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lower_band(stock):\n",
    "    # sorted_data = pd.DataFrame()\n",
    "    # sorted_data[\"Date\"] = stock[\"Date\"]\n",
    "    # sorted_data[\"Close Price\"] = stock[\"Close Price\"]\n",
    "    # sorted_data[\"Date\"] = pd.to_datetime(sorted_data[\"Date\"])\n",
    "    # stock[\"Date\"] = pd.to_datetime(stock[\"Date\"])\n",
    "    # sorted_data = sorted_data.sort_values(['Close Price', 'Date'], ascending=[True, False])\n",
    "    # start_date = stock.tail(1)[\"Date\"].values[0]\n",
    "\n",
    "    stock[\"Lower Band\"]=\"\"\n",
    "    for i,row in stock.iterrows():\n",
    "        # end_date = row[\"Date\"]\n",
    "        # close_price = row[\"Close Price\"]\n",
    "        stock.loc[i,\"Lower Band\"] = min(stock.loc[i:][\"Close Price\"])\n",
    "        # specific_dates = stock[stock.Date.between(start_date,end_date)]\n",
    "        # for index,j in specific_dates.iterrows():\n",
    "        #     stock.iloc[index,\"Lower Band\"] = close_price\n",
    "    return stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_upper_band(stock):\n",
    "    # sorted_data = pd.DataFrame()\n",
    "    # sorted_data[\"Date\"] = stock[\"Date\"]\n",
    "    # sorted_data[\"Close Price\"] = stock[\"Close Price\"]\n",
    "    # sorted_data[\"Date\"] = pd.to_datetime(sorted_data[\"Date\"])\n",
    "    # stock[\"Date\"] = pd.to_datetime(stock[\"Date\"])\n",
    "    # sorted_data = sorted_data.sort_values(['Close Price', 'Date'], ascending=[False, True])\n",
    "    # end_date = stock.tail(1)[\"Date\"].values[0]\n",
    "    stock[\"Upper Band\"]=\"\"\n",
    "    for i,row in stock.iterrows():\n",
    "        # start_date = row[\"Date\"]\n",
    "        # close_price = row[\"Close Price\"]\n",
    "        stock.loc[i,\"Upper Band\"] = max(stock.loc[i:][\"Close Price\"])\n",
    "        # specific_dates = stock[stock.Date.between(start_date,end_date)]\n",
    "        # for index,j in specific_dates.iterrows():\n",
    "            # stock.loc[index,\"Upper Band\"] = close_price\n",
    "    return stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_band_area(stock):\n",
    "    stock[\"Upper Band\"] = pd.to_numeric(stock[\"Upper Band\"])\n",
    "    stock[\"Lower Band\"] = pd.to_numeric(stock[\"Lower Band\"])\n",
    "    stock[\"Band Area\"] = stock[\"Upper Band\"]-stock[\"Lower Band\"]\n",
    "    return stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lower_upper_bands(stock):\n",
    "    stock[\"Lower Band\"]=\"\"\n",
    "    stock[\"Upper Band\"]=\"\"\n",
    "    stock[\"Band Area\"] = \"\"\n",
    "\n",
    "    for i,row in stock.iterrows():\n",
    "        maxv = max(stock.loc[i:][\"Close Price\"])\n",
    "        minv = min(stock.loc[i:][\"Close Price\"])\n",
    "        stock.loc[i,\"Upper Band\"] = maxv\n",
    "        stock.loc[i,\"Lower Band\"] = minv\n",
    "        stock.loc[i,\"Band Area\"] = maxv - minv\n",
    "    return stock\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock_df = create_lower_upper_bands(stock_df)"
   ]
  },
  {
   "source": [
    "# create eps, pe_ratio, revenue, income, expenditure, profit"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_eps_pe_ratio_revenue_income_expenditure_net_profit(rev,stk):\n",
    "    stk[\"Date\"] = pd.to_datetime(stk[\"Date\"])\n",
    "    s = min(rev.year)\n",
    "    e = max(rev.year)\n",
    "    cols = ['Revenue','Income','Expenditure','Net Profit','EPS']\n",
    "    stk[cols] = pd.DataFrame([[0]*len(cols)], index=stk.index)\n",
    "\n",
    "    rep = ['revenue','income','expenditure','profit','eps']\n",
    "\n",
    "    for index,row in stk.iterrows():\n",
    "        q = (row.Date.month-1)//3 + 1\n",
    "        samp = rev[(rev['year']==row.Date.year)&(rev['quartile']==q)]\n",
    "        if samp.shape[0] !=0:\n",
    "            stk.loc[index,cols] = samp.iloc[0][rep].values\n",
    "        else:\n",
    "            stk.loc[index,cols] = [np.nan]*5\n",
    "        \n",
    "    stk['year'] = pd.DatetimeIndex(stk['Date']).year\n",
    "    # stk = stk[(stk.year >= s)&(stk.year <= e) & stk[\"Revenue\"] !=0 ]\n",
    "    # stk = stk.drop([\"year\"],axis=1)\n",
    "\n",
    "    bands = [2,4,8]\n",
    "\n",
    "    for band in bands:\n",
    "        bcols = ['Revenue last '+str(band)+' quarters','Income last '+str(band)+' quarters','Expenditure  last '+str(band)+' quarters','Net Profit  last '+str(band)+' quarters','EPS last '+str(band)+' quarters']\n",
    "        stk[bcols] = pd.DataFrame([[0]*len(bcols)], index=stk.index)\n",
    "\n",
    "        for index,row in stk.iterrows():\n",
    "            q = (row.Date.month-1)//3 + 1\n",
    "            samp = rev[(rev['year']==row.Date.year)&(rev['quartile']==q)]\n",
    "            if samp.shape[0] == 0:\n",
    "                r = 1\n",
    "            else:\n",
    "                r = samp.index.values[0]\n",
    "            if r+band+1 < rev.shape[0]:\n",
    "                v = range(r+1,r+band+1)\n",
    "                stk.loc[index,bcols] = rev.loc[v,rep].sum().values\n",
    "    stk[\"p/e\"] = stk[\"Close Price\"]/stk[\"EPS\"]\n",
    "    return stk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock_df = create_eps_pe_ratio_revenue_income_expenditure_net_profit(revenue_df,stock_df)"
   ]
  },
  {
   "source": [
    "#  Create Next Day Columns"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_next_day_columns(stock):\n",
    "    new_columns = [\"Next Day Open Price\",\"Next Day High Price\",\"Next Day Low Price\",\"Next Day Close Price\"]\n",
    "    columns = [\"Open Price\",\"High Price\",\"Low Price\",\"Close Price\"]\n",
    "    stock[new_columns] = pd.DataFrame([[0,0,0,0]], index=stock.index)\n",
    "    stock[new_columns] = stock[columns].shift(1)\n",
    "    return stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock_df = add_next_day_columns(stock_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock_df.to_csv(os.path.join(path,\"Data/Stock/\"+\"fc\"+str(security_id)+\".csv\"),index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock_df = pd.read_csv(os.path.join(path,\"Data/Stock/\"+\"fc\"+str(security_id)+\".csv\"))"
   ]
  },
  {
   "source": [
    "# Growth Rate Features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "direct_columns = ['Open Price', 'High Price', 'Low Price', 'Close Price','Next Day Open Price', 'Next Day High Price', 'Next Day Low Price', 'Next Day Close Price','WAP','No.of Shares', 'No. of Trades', 'Total Turnover (Rs.)','Deliverable Quantity', '% Deli. Qty to Traded Qty','Spread High-Low','Spread Close-Open','Alpha','Beta']\n",
    "growth_direct_rate_columns = [col + \" GR\" for col in direct_columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock_df[direct_columns] = stock_df[direct_columns].apply(pd.to_numeric,errors=\"coerce\")"
   ]
  },
  {
   "source": [
    "## Direct Growth Rate Columns"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_gain_loss(stock):\n",
    "    stock[direct_columns] = stock[direct_columns].apply(pd.to_numeric,errors=\"coerce\")\n",
    "    stock[growth_direct_rate_columns] = pd.DataFrame([[0]*len(growth_direct_rate_columns)], index=stock.index)\n",
    "    today = stock[direct_columns]\n",
    "    previous = stock[direct_columns].shift(1)\n",
    "    stock[growth_direct_rate_columns] = (today-previous)/previous\n",
    "    return stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock_df = find_gain_loss(stock_df)"
   ]
  },
  {
   "source": [
    "# Sequential Increase"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequential_increase(stock):\n",
    "    stock[\"Sequential Increase\"] = \"\"\n",
    "    c = 0\n",
    "    stock.at[stock.shape[0]-2, \"Sequential Increase\"] = 0\n",
    "    stock.at[stock.shape[0]-1, \"Sequential Increase\"] = 0\n",
    "    for i in range(stock.shape[0]-2, 0, -1):\n",
    "        if stock.at[i,\"Close Price\"] > stock.at[i+1,\"Close Price\"]:\n",
    "            c += 1\n",
    "            stock.at[i-1,\"Sequential Increase\"] = c\n",
    "        else:\n",
    "            stock.at[i-1,\"Sequential Increase\"] = 0\n",
    "            c = 0\n",
    "    return stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock_df = sequential_increase(stock_df)"
   ]
  },
  {
   "source": [
    "# Sequential Decrease"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequential_decrease(stock):\n",
    "    stock[\"Sequential Decrease\"] = 0\n",
    "    c = 1\n",
    "    stock.at[stock.shape[0]-2, \"Sequential Decrease\"] = 0\n",
    "    stock.at[stock.shape[0]-1, \"Sequential Decrease\"] = 0\n",
    "    for i in range(stock.shape[0]-2, 0, -1):\n",
    "        if stock.at[i,\"Close Price\"] < stock.at[i+1,\"Close Price\"]:\n",
    "            stock.at[i-1,\"Sequential Decrease\"] = c\n",
    "            c += 1\n",
    "        else:\n",
    "            stock.at[i-1,\"Sequential Decrease\"] = 0\n",
    "            c = 1\n",
    "    return stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock_df = sequential_decrease(stock_df)"
   ]
  },
  {
   "source": [
    "# Sequential Increase Percentage"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequential_increase_percentage(stock):\n",
    "    stock[\"Sequential Increase %\"] = \"\"\n",
    "    for i in range(stock.shape[0]-2):\n",
    "        if stock.at[i, \"Sequential Increase\"] != 0:\n",
    "            inc = stock.at[i, \"Sequential Increase\"]\n",
    "        else:\n",
    "            inc = 1\n",
    "        fr = stock.at[i+1, \"Close Price\"]\n",
    "        to = stock.at[i+1+inc, \"Close Price\"]\n",
    "        stock.at[i, \"Sequential Increase %\"] = (fr - to) / to\n",
    "    stock.at[stock.shape[0]-2, \"Sequential Increase %\"] = 0\n",
    "    stock.at[stock.shape[0]-1, \"Sequential Increase %\"] = 0\n",
    "    return stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock_df = sequential_increase_percentage(stock_df)"
   ]
  },
  {
   "source": [
    "# Sequential Decrease Percentage"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequential_decrease_percentage(stock):\n",
    "    stock[\"Sequential Decrease %\"] = \"\"\n",
    "    for i in range(stock.shape[0]-2):\n",
    "        if stock.at[i, \"Sequential Decrease\"] != 0:\n",
    "            inc = stock.at[i, \"Sequential Decrease\"]\n",
    "        else:\n",
    "            inc = 1\n",
    "        fr = stock.at[i+1, \"Close Price\"]\n",
    "        to = stock.at[i+1+inc, \"Close Price\"]\n",
    "        stock.at[i, \"Sequential Decrease %\"] = (to - fr) / fr\n",
    "    stock.at[stock.shape[0]-2, \"Sequential Decrease %\"] = 0\n",
    "    stock.at[stock.shape[0]-1, \"Sequential Decrease %\"] = 0\n",
    "    return stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock_df = sequential_decrease_percentage(stock_df)"
   ]
  },
  {
   "source": [
    "# Sequential max min avg increase, max min avg decrease for 90, 180, 365 days"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_min_avg_of_sequential_data(stock):\n",
    "    index_start = stock.first_valid_index() \n",
    "    seq_inc_days = stock.at[index_start, \"Sequential Increase\"]\n",
    "    seq_dec_days = stock.at[index_start, \"Sequential Decrease\"]\n",
    "    seq_inc_list = [0]\n",
    "    seq_dec_list = [0]\n",
    "    for i in range(index_start, stock.shape[0]+index_start):\n",
    "        if stock.at[i, \"Sequential Increase\"] == seq_inc_days:\n",
    "            seq_inc_list.append(stock.at[i, \"Sequential Increase %\"])\n",
    "        if stock.at[i, \"Sequential Decrease\"] == seq_dec_days:\n",
    "            seq_dec_list.append(stock.at[i, \"Sequential Decrease %\"])\n",
    "    seq_inc_list = [i for i in seq_inc_list if i != 0 and i]\n",
    "    seq_dec_list = [i for i in seq_dec_list if i != 0 and i]\n",
    "    return seq_inc_list, seq_dec_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequential_increase_decrease(stock):\n",
    "    bands = [90,180,365]\n",
    "    for b in bands:\n",
    "        bcols = [\"Max Inc % in \"+str(b)+\" days\",\"Max Dec % in \"+str(b)+\" days\",\"Min Inc % in \"+str(b)+\" days\",\"Min Dec % in \"+str(b)+\" days\",\"Avg Inc % in \"+str(b)+\" days\",\"Avg Dec % in \"+str(b)+\" days\"]\n",
    "        stock[bcols] = pd.DataFrame([[0]*len(bcols)], index=stock.index)\n",
    "        for i in range(stock.shape[0]):\n",
    "            s = i+1\n",
    "            specific_bands = stock.iloc[-(s):-(s+b+1):-1]\n",
    "            specific_bands.sort_index(inplace=True)\n",
    "            seq_inc_list, seq_dec_list = max_min_avg_of_sequential_data(specific_bands)\n",
    "            try:\n",
    "                stock.loc[specific_bands.index,bcols] = [max(seq_inc_list),max(seq_dec_list),min(seq_inc_list),min(seq_dec_list),np.mean(seq_inc_list),np.mean(seq_dec_list)]\n",
    "            except:\n",
    "                continue\n",
    "    return stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock_df = sequential_increase_decrease(stock_df)"
   ]
  },
  {
   "source": [
    "# QuaterWise growth rate for \"Revenue\",\"Dividend\",\"Income\",\"Expenditure\",\"Net Profit\",\"EPS\""
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"Revenue\",\"Dividend Value\",\"Income\",\"Expenditure\",\"Net Profit\",\"EPS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dictionary_for_quarterwise_data(stock,columnName):\n",
    "    result = {}\n",
    "    stock.Date = pd.to_datetime(stock.Date)\n",
    "    for index,row in stock.iterrows():\n",
    "        q = (row.Date.month-1)//3 + 1   \n",
    "        year = row.Date.year\n",
    "        month = row.Date.month\n",
    "        res = result.get(year,{})\n",
    "        # amount = re.findall(r\"\\d+.?\\d*\",row[\"Revenue\"])[0]\n",
    "        amount  = row[columnName]\n",
    "        q = \"1q\" if 1 <= month <= 3 else \"2q\" if 4 <= month <= 6 else \"3q\" if 6 <= month <= 9 else \"4q\"\n",
    "        val = res.get(q,[])\n",
    "        val.append(float(amount))\n",
    "        res[q] = val\n",
    "        result[year] = res\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dictionary_for_quarterwise_growthrate_data(data):\n",
    "    gr_dic = {}\n",
    "    keys = list(data.keys())\n",
    "    array = [''] * (len(keys)*4)\n",
    "    array_index = 0\n",
    "    for key in data:\n",
    "        lists = data.get(key)\n",
    "        array_index += 4 - len(lists.keys()) \n",
    "        for lis in lists:\n",
    "            if math.isnan(lists.get(lis)[0]):\n",
    "                array[array_index] = ''\n",
    "            else:                \n",
    "                array[array_index] = lists.get(lis)[0]\n",
    "            array_index = array_index + 1\n",
    "    if (array.count('')) > ((len(keys) * 4) / 2):\n",
    "        return gr_dic\n",
    "    \n",
    "    for i in range(4,len(keys)*4,4):\n",
    "        res = [array[i],array[i+1],array[i+2],array[i+3]]\n",
    "        avg = np.mean(list(filter(lambda i: isinstance(i, float), res)))\n",
    "        if np.isnan(avg):\n",
    "            pass\n",
    "        else:\n",
    "            array[i] = avg\n",
    "\n",
    "    gr_array = [''] * (len(keys)*4)\n",
    "    for i in range(0, len(keys)*4-1):\n",
    "        x = array[i]\n",
    "        y = array[i+1]\n",
    "        if x == '' and y == '': continue\n",
    "        if y == '' or y == 0: continue\n",
    "        if x == '':\n",
    "            gr_array[i] = 1\n",
    "        else:\n",
    "            gr_array[i] = (x - y) / y\n",
    "    index = 0\n",
    "    for key in data:\n",
    "        gr_dic[key] = [gr_array[index], gr_array[index+1], gr_array[index+2], gr_array[index+3]]\n",
    "        index = index + 4\n",
    "    return gr_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_growthrate_for_quarterwise_data(gr_dic, stock, columnName):\n",
    "    for i in range(0, stock.shape[0]-1):\n",
    "        date = stock.at[i, \"Date\"]\n",
    "        q = int((date.month-1)//3)\n",
    "        year = date.year\n",
    "        if year in gr_dic.keys():\n",
    "            stock.at[i,columnName+\" GR\"] = gr_dic.get(year)[q] if isinstance(gr_dic.get(year)[q],float) else 0\n",
    "    return stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quarter_wise_growthrate(stock, columnName):\n",
    "    dic = generate_dictionary_for_quarterwise_data(stock, columnName)\n",
    "    gr_dic = generate_dictionary_for_quarterwise_growthrate_data(dic)\n",
    "    stock[columnName + ' GR'] = ''\n",
    "    if gr_dic == {}:\n",
    "        return stock\n",
    "    else:\n",
    "        stock = update_growthrate_for_quarterwise_data(gr_dic, stock, columnName)\n",
    "    return stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in cols:\n",
    "#     try:\n",
    "#         stock_df = quarter_wise_growthrate(stock_df, col)\n",
    "#     except:\n",
    "#         pass"
   ]
  },
  {
   "source": [
    "# Close Price as percentage of Lowest Value, Highest Value, Band Area for 7, 30, 90, 180, 365 days"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def close_price_as_percent_of_LV_HV_BA(stock):\n",
    "    bands = [7,30,90,180,365]\n",
    "    for b in bands:\n",
    "        bcols = [\"CP % LV \"+str(b)+\" days\",\"CP % HV \"+str(b)+\" days\",\"CP % BA \"+str(b)+\" days\"]\n",
    "        stock[bcols] = pd.DataFrame([[0]*len(bcols)], index=stock.index)\n",
    "        for i in range(stock.shape[0]):\n",
    "            s = i+1\n",
    "            specific_bands = stock.iloc[-(s):-(s+b+1):-1]\n",
    "            low = specific_bands[\"Close Price\"].min()\n",
    "            high = specific_bands[\"Close Price\"].max()\n",
    "            today = stock.iloc[-(s)][\"Close Price\"]\n",
    "            stock.loc[specific_bands.index,bcols] = [today/low,today/high,today/(high-low)]\n",
    "    return stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock_df = close_price_as_percent_of_LV_HV_BA(stock_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock_df.to_csv(os.path.join(path,\"Data/Stock/\"+\"gr\"+str(security_id)+\".csv\"),index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top = pd.read_csv(\"top.csv\")"
   ]
  },
  {
   "source": [
    "# For full Stock"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cols = [\"Revenue\",\"Dividend Value\",\"Income\",\"Expenditure\",\"Net Profit\",\"EPS\"]\n",
    "for _,row in top.iterrows():\n",
    "    start = time.time()\n",
    "    security_id = str(row[\"security id\"])\n",
    "    name = row[\"name\"]\n",
    "    try:\n",
    "        index_df = pd.read_csv(os.path.join(path,\"Data/Index.csv\"))\n",
    "        corporate_df = pd.read_csv(os.path.join(path,\"Data/CorporateActions/\"+security_id+\".csv\"))\n",
    "        revenue_df = pd.read_csv(os.path.join(path,\"Data/Revenue/\"+security_id+\".csv\"))\n",
    "        stock_df = pd.read_csv(os.path.join(path,\"Data/Stock/\"+security_id+\".csv\"))\n",
    "\n",
    "        stock_df = cleaning(stock_df,index_df)\n",
    "        stock_df = apply_corporate_actions(stock_df,corporate_df)\n",
    "        create_index()\n",
    "        stock_df = calculate_beta(stock_df)\n",
    "        stock_df = add_risk_free_column(stock_df)\n",
    "        stock_df = calculate_alpha(stock_df)\n",
    "        stock_df = create_lower_upper_bands(stock_df)\n",
    "        stock_df = create_eps_pe_ratio_revenue_income_expenditure_net_profit(revenue_df,stock_df)\n",
    "        stock_df = add_next_day_columns(stock_df)\n",
    "\n",
    "        stock_df.to_csv(os.path.join(path,\"Data/Stock/\"+\"fc\"+str(security_id)+\".csv\"),index=None)\n",
    "        stock_df = pd.read_csv(os.path.join(path,\"Data/Stock/\"+\"fc\"+str(security_id)+\".csv\"))\n",
    "\n",
    "        stock_df[direct_columns] = stock_df[direct_columns].apply(pd.to_numeric,errors=\"coerce\")\n",
    "        stock_df = find_gain_loss(stock_df)\n",
    "        stock_df = sequential_increase(stock_df)\n",
    "        stock_df = sequential_decrease(stock_df)\n",
    "        stock_df = sequential_increase_percentage(stock_df)\n",
    "        stock_df = sequential_decrease_percentage(stock_df)\n",
    "        stock_df = sequential_increase_decrease(stock_df)\n",
    "\n",
    "        for col in cols:\n",
    "            try:\n",
    "                stock_df = quarter_wise_growthrate(stock_df, col)\n",
    "            except Exception as e:\n",
    "                print(e,\"---\")\n",
    "\n",
    "        stock_df = close_price_as_percent_of_LV_HV_BA(stock_df)\n",
    "        stock_df.to_csv(os.path.join(path,\"Data/Stock/\"+\"gr\"+str(security_id)+\".csv\"),index=None)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e,\"***\")\n",
    "        end = time.time()\n",
    "        print(security_id,\" = \", end-start)\n",
    "    else:\n",
    "        end = time.time()\n",
    "        print(security_id,\" = \", end-start)\n",
    "    print(\"------------------------------\")\n",
    "    "
   ]
  },
  {
   "source": [
    "# For New Stock Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "security_id = \"500680\"\n",
    "name = \"PFIZER LTD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_df = pd.read_csv(os.path.join(path,\"Data/Index.csv\"))\n",
    "corporate_df = pd.read_csv(os.path.join(path,\"Data/CorporateActions/\"+security_id+\".csv\"))\n",
    "revenue_df = pd.read_csv(os.path.join(path,\"Data/Revenue/\"+security_id+\".csv\"))\n",
    "stock_df = pd.read_csv(os.path.join(path,\"Data/Stock/\"+\"new\"+security_id+\".csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_df = cleaning(stock_df,index_df)\n",
    "stock_df = apply_corporate_actions(stock_df,corporate_df)\n",
    "create_index()\n",
    "stock_df = calculate_beta(stock_df)\n",
    "stock_df = add_risk_free_column(stock_df)\n",
    "stock_df = calculate_alpha(stock_df)\n",
    "old_df = pd.read_csv(os.path.join(path,\"Data/Stock/\"+\"fc\"+security_id+\".csv\"))\n",
    "stock_df = stock_df.append(old_df.head(5),ignore_index=True)\n",
    "stock_df.Date = pd.to_datetime(stock_df.Date)\n",
    "stock_df = stock_df.sort_values(by=[\"Date\"],ascending=[False])\n",
    "stock_df = create_lower_upper_bands(stock_df)\n",
    "stock_df = create_eps_pe_ratio_revenue_income_expenditure_net_profit(revenue_df,stock_df)\n",
    "stock_df = add_next_day_columns(stock_df)\n",
    "old_df = stock_df.append(old_df,ignore_index=True)\n",
    "old_df.Date = pd.to_datetime(old_df.Date)\n",
    "old_df.drop_duplicates(subset=[\"Date\"],inplace=True)\n",
    "old_df.to_csv(os.path.join(path,\"Data/Stock/\"+\"fc\"+str(security_id)+\".csv\"),index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_df.drop_duplicates(subset=[\"Unix Date\"],ignore_index=True)\n",
    "stock_df[direct_columns] = stock_df[direct_columns].astype(float)\n",
    "stock_df[direct_columns] = stock_df[direct_columns].astype(float)\n",
    "stock_df = find_gain_loss(stock_df)\n",
    "stock_df = sequential_increase(stock_df)\n",
    "stock_df = sequential_decrease(stock_df)\n",
    "stock_df = sequential_increase_percentage(stock_df)\n",
    "stock_df = sequential_decrease_percentage(stock_df)\n",
    "stock_df = sequential_increase_decrease(stock_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cols:\n",
    "    try:\n",
    "        stock_df = quarter_wise_growthrate(stock_df, col)\n",
    "    except Exception as e:\n",
    "        print(e,\"---\")\n",
    "stock_df = close_price_as_percent_of_LV_HV_BA(stock_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_df = pd.read_csv(os.path.join(path,\"Data/Stock/\"+\"gr\"+str(security_id)+\".csv\"))\n",
    "stock_df = stock_df.append(old_df,ignore_index=True)\n",
    "stock_df.drop_duplicates(subset=[\"Unix Date\"],inplace=True)\n",
    "stock_df.to_csv(os.path.join(path,\"Data/Stock/\"+\"gr\"+str(security_id)+\".csv\"),index=None)\n",
    "os.remove(os.path.join(path,\"Data/Stock/\"+\"new\"+str(security_id)+\".csv\"))"
   ]
  }
 ]
}