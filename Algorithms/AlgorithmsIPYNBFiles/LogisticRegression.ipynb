{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "2db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "from math import sqrt\n",
    "import statsmodels.api as sm\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import time \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cmx\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.patches as patches\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import math\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import dataframe_image as dfi\n",
    "import traceback\n",
    "import prettytable\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "path"
   ]
  },
  {
   "source": [
    "# PreProcessing Data    "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_data(data,null_threshold):\n",
    "    \"\"\"\n",
    "    Drops Date and Unix Date columns from the data.\n",
    "    Drops the columns which has null values more than specified null_threshold.\n",
    "    Replaces infinite values with NAN.\n",
    "    Drops the rows which has null values.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : dataframe\n",
    "\n",
    "    null_threshold : numeric\n",
    "        numeric value describing the amount of null values that can be present.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data : dataframe\n",
    "        an updated dataframe after performing all the opertaions.\n",
    "    \"\"\"\n",
    "    \n",
    "    data.drop(columns=['Unix Date','Date'],axis=1,inplace=True)\n",
    "    total = data.shape[0]\n",
    "    for col in data.columns:\n",
    "        if null_threshold * total / 100 < data[col].isnull().sum():\n",
    "            data.drop(columns=[col],axis=1,inplace=True)\n",
    "    data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    data.dropna(axis=0,inplace=True)\n",
    "    return data"
   ]
  },
  {
   "source": [
    "# Removing columns based on dependent column\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dependent_column(data,column):\n",
    "    \"\"\"\n",
    "    Removes all the Next Day columns.\n",
    "    Removes all the non Growth Rate Columns (GR)\n",
    "    add the predictor column to list of columns.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : dataframe\n",
    "\n",
    "    column : string\n",
    "        name of the predictor column \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data : dataframe\n",
    "        an updated dataframe after performing all the opertaions.\n",
    "    column : string\n",
    "        name of the predictor column\n",
    "    \"\"\"\n",
    "    cols = [col for col in data.columns if \"next\" not in col.lower() and col.lower().endswith(\"gr\")]\n",
    "    cols.append(column)\n",
    "    data = data[cols]\n",
    "    return (data,column)"
   ]
  },
  {
   "source": [
    "# Parameters Tuning"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameters_tuning(penalty,C,X_train, y_train):\n",
    "    logistic = LogisticRegression()\n",
    "    hyperparameters = dict(C=C, penalty=penalty)\n",
    "    try:\n",
    "        clf = GridSearchCV(logistic, hyperparameters, cv=5, verbose=0)\n",
    "        best_model = clf.fit(X_train, y_train)\n",
    "    except:\n",
    "        hyperparameters[\"penalty\"] = ['none','l2']\n",
    "        clf = GridSearchCV(logistic, hyperparameters, cv=5, verbose=0)\n",
    "        best_model = clf.fit(X_train, y_train)\n",
    "    penalty = best_model.best_estimator_.get_params()[\"penalty\"]\n",
    "    C = best_model.best_estimator_.get_params()[\"C\"]\n",
    "    return (penalty,C)\n"
   ]
  },
  {
   "source": [
    "# OLS Regression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OLS_Regression(X_train,Y_train):\n",
    "    X_train = np.array(X_train, dtype=float)\n",
    "    ols_model = sm.OLS(Y_train, X_train).fit()\n",
    "    rsquared_adj = ols_model.rsquared_adj\n",
    "    aic = ols_model.aic\n",
    "    bic = ols_model.bic\n",
    "    fvalue = ols_model.fvalue\n",
    "    return {\"rsquared_adj\":rsquared_adj,\"aic\":aic,\"bic\":bic,\"fvalue\":fvalue}"
   ]
  },
  {
   "source": [
    "# Confusion Matrix\n",
    "\n",
    "### true negatives  {0,0},\n",
    "### false negatives {1,0},\n",
    "### true positives  {1,1},\n",
    "### false positives {0,1}."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_confusion_matrix(y_pred,y_true):\n",
    "    \n",
    "    cm = confusion_matrix(y_true,y_pred)\n",
    "    accuracy = metrics.accuracy_score(y_true,y_pred)\n",
    "    precision = metrics.precision_score(y_true,y_pred)\n",
    "    recall = metrics.recall_score(y_true,y_pred)\n",
    "    f1_score = metrics.f1_score(y_true,y_pred)\n",
    "    return {\"accuracy\":accuracy,\"precision\":precision,\"recall\":recall,\"f1_score\":f1_score,\"confusion matrix\":cm}\n",
    "\n",
    "    # accuracy = float(cm.diagonal().sum())/len(y_test)\n",
    "    # TN = cm[0][0]\n",
    "    # FP = cm[0][1]\n",
    "    # FN = cm[1][0]\n",
    "    # TP = cm[1][1]\n",
    "    \n",
    "    # precision1 = TP / (TP + FP)\n",
    "    # precision1 = 0 if math.isnan(precision1) else precision1\n",
    "    \n",
    "    # recall1 = TP / (TP + FN)\n",
    "    # recall1 = 0 if math.isnan(recall1) else recall1\n",
    "\n",
    "    # f_measure = (2 * precision1 * recall1)/(precision1 + recall1)\n",
    "    \n",
    "    # precision0 = TN / (TN + FN)\n",
    "    # precision0 = 0 if math.isnan(precision0) else precision0\n",
    "    \n",
    "    # recall0 = TN / (FP  + TN)\n",
    "    # recall0 = 0 if math.isnan(recall0) else recall0\n"
   ]
  },
  {
   "source": [
    "# Logistic Regression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(df,threshold):\n",
    "    df[\"Target\"] = df[\"NextDay Close Price GR\"].apply(lambda x : 1 if x >= threshold else 0)\n",
    "    X = df[df.columns[:-2]]\n",
    "    Y = df[\"Target\"]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=0)\n",
    "    penalty = ['l1', 'l2','none']\n",
    "    C = [0.001,0.01,0.1,1,10,100]\n",
    "    penalty,C = parameters_tuning(penalty,C,X_train, y_train)\n",
    "    logmodel = LogisticRegression(penalty = penalty, C = C,random_state = 0)\n",
    "    logmodel.fit(X_train, y_train)\n",
    "    y_pred = logmodel.predict(X_test)\n",
    "\n",
    "    confidence = logmodel.score(X_test, y_test)\n",
    "    rmse = sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "    mae = metrics.mean_absolute_error(y_test, y_pred)\n",
    "    mse = metrics.mean_squared_error(y_test, y_pred)\n",
    "    confusion_mat =  create_confusion_matrix(y_pred,y_test)\n",
    "    ols_values = OLS_Regression(X_train,y_train)\n",
    "    myres = {\"root_mean_squared_error\":rmse,\"mean_absolute_error\":mae,\"mean_squared_error\":mse,\"confidence\":confidence}\n",
    "    myres.update(confusion_mat)\n",
    "    myres.update({\"f-value\":ols_values[\"fvalue\"]})\n",
    "    return myres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top = pd.read_csv('top.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df_cols = ['features', 'threshold', 'pvalue', 'fvalue','root_mean_squared_error','mean_absolute_error', 'mean_squared_error', 'confidence', 'accuracy',\n",
    "       'precision', 'recall', 'f1_score', 'f-value',\"confusion matrix\"]\n",
    "for _,row in top.iterrows():\n",
    "    stock_result = pd.DataFrame(columns=df_cols)\n",
    "    name = row['security id']\n",
    "    company = {}\n",
    "    df = pd.read_csv(os.path.join(path,\"Data\\Stock\\\\\"+\"gr\"+str(name)+\".csv\"))\n",
    "    df = pre_process_data(df,60)\n",
    "    column = \"Next Day Close Price GR\"\n",
    "    (df,column) = dependent_column(df,column)\n",
    "\n",
    "    threshold_values = [0.01,0.02,0.03,0.04,0.05,0.06,0.07,0.08,0.09,0.1]\n",
    "    for threshold in threshold_values:\n",
    "        try:\n",
    "            target = df[\"Next Day Close Price GR\"].apply(lambda x : 1 if x >= threshold else 0)\n",
    "            X = df[df.columns[:-2]]\n",
    "            Y = target\n",
    "            fvalues, pvalues = f_classif(X,Y)\n",
    "            fvalues = dict(zip(X.columns,fvalues))\n",
    "            pvalues = dict(zip(X.columns,pvalues))\n",
    "            dataset = []\n",
    "            p_range = [0.05,0.1,0.15,0.2,0.25]\n",
    "            for p in p_range:\n",
    "                mycols = list()\n",
    "                for col,val in pvalues.items():\n",
    "                    if val <= p:\n",
    "                        mycols.append(col)\n",
    "                if mycols == []:\n",
    "                    res = {\"features\":mycols,\"threshold\":threshold,\"pvalue\":p}\n",
    "                    dataset.append(res)\n",
    "                    continue\n",
    "                res = logistic_regression(df[mycols+[column]],threshold)\n",
    "                fsol = [b for a,b in fvalues.items() if a in mycols]\n",
    "                rf = np.max(fsol)\n",
    "                res.update({\"features\":mycols,\"threshold\":threshold,\"pvalue\":p,\"fvalue\":rf})\n",
    "                dataset.append(res)\n",
    "\n",
    "            f_range = [0.1,0.5,1,2,5,10,100]\n",
    "            for f in f_range:\n",
    "                mycols = list()\n",
    "                for col,val in fvalues.items():\n",
    "                    if val >= f:\n",
    "                        mycols.append(col)\n",
    "\n",
    "                if mycols == []:\n",
    "                    res = {\"features\":mycols,\"threshold\":threshold,\"fvalue\":f}\n",
    "                    dataset.append(res)\n",
    "                    continue\n",
    "                res = logistic_regression(df[mycols+[column]],threshold)\n",
    "                psol = [b for a,b in pvalues.items() if a in mycols]\n",
    "                rp = np.max(psol)\n",
    "                res.update({\"features\":mycols,\"threshold\":threshold,\"fvalue\":f,\"pvalue\":rp})\n",
    "                dataset.append(res)\n",
    "        except Exception as e:\n",
    "            traceback.print_exc()\n",
    "        res_df = pd.DataFrame(dataset)\n",
    "        stock_result = stock_result.append(res_df,ignore_index=True)\n",
    "    stock_result.to_csv(os.path.join(path,\"Results\\\\\"+str(name)+\"_logistic\"+\".csv\"),index=None,float_format=\"%.6f\")"
   ]
  },
  {
   "source": [
    "# Pretty Table"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top = pd.read_csv(\"top.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tcols = ['threshold', 'pvalue', 'fvalue', 'root_mean_squared_error','mean_absolute_error', 'mean_squared_error', 'accuracy','precision', 'recall', 'f1_score']\n",
    "best_df_cols = [\"security id\",\"name\",\"threshold\",\"pvalue\",\"fvalue\"]\n",
    "best_df = pd.DataFrame()\n",
    "for filename in os.listdir(os.path.join(path,\"Results\")):\n",
    "    if filename.endswith(\"_logistic.csv\"):\n",
    "        log_df = pd.read_csv(os.path.join(path,\"Results\\\\\"+filename))\n",
    "        stock_name = top[top[\"security id\"] == int(filename[:6])][\"name\"].values[0]\n",
    "        log_df.fvalue = log_df.fvalue.apply(np.ceil)\n",
    "        log_df = log_df[tcols]\n",
    "        log_df.dropna(how='any',inplace=True)\n",
    "        table = prettytable.PrettyTable()\n",
    "        table.field_names = tcols\n",
    "        table.title = stock_name + \" \" + filename[:-4]\n",
    "        for _, row in log_df.iterrows():\n",
    "            row = [round(r,6) for r in row]\n",
    "            table.add_row(row)\n",
    "        print(table)\n",
    "        log_df[\"security id\"] = filename[:6]\n",
    "        log_df[\"name\"] = stock_name\n",
    "        for name, log in log_df.groupby(by=[\"threshold\"]):\n",
    "            log.sort_values(by=[\"f1_score\"],ascending=[False])\n",
    "            best_df = best_df.append(log[best_df_cols].head(1),ignore_index=True)\n",
    "best_df.to_csv(os.path.join(path,\"Results\\\\\"+\"best_logistic_model\"+\".csv\"),index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = prettytable.PrettyTable()\n",
    "best_model.field_names = best_df_cols\n",
    "best_model.title = \"logistic regression best model for each stock\"\n",
    "for _, row in best_df.iterrows():\n",
    "    row = [round(r,6) if isinstance(r,float) else r for r in row]\n",
    "    best_model.add_row(row)\n",
    "print(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}