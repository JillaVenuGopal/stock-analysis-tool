{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python394jvsc74a57bd0d87dce8391821cf63a3c66fecb51d752844feaef4dc8e3007d3ff39793894683",
   "display_name": "Python 3.9.4 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import traceback\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pandas as pd\n",
    "import time\n",
    "import calendar\n",
    "from datetime import datetime\n",
    "import datetime\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from multiprocessing.pool import ThreadPool\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'f:\\\\PracticumProject\\\\stock-analysis-tool'"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "path = os.getcwd()\n",
    "path"
   ]
  },
  {
   "source": [
    "# Scraping of Equity Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_equity():\n",
    "    \"\"\"\n",
    "    download the equity file.\n",
    "\n",
    "    if file already exists, returns None\n",
    "\n",
    "    security_url = \"https://www.bseindia.com/corporates/List_Scrips.aspx\"\n",
    "    \n",
    "    creates the driver.\n",
    "\n",
    "    opens the security_url.\n",
    "    \n",
    "    Sets Active and Equity fields.\n",
    "    \n",
    "    downloads the file.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    path = os.path.join(os.getcwd(),\"Data\")\n",
    "    security_url = \"https://www.bseindia.com/corporates/List_Scrips.aspx\"\n",
    "\n",
    "    if os.path.exists(os.path.join(path,\"Equity.csv\")):\n",
    "        print(\"Equity.csv exists\")\n",
    "        return\n",
    "\n",
    "    chromeOptions = webdriver.ChromeOptions()\n",
    "    chromeOptions.add_argument(\"--headless\")\n",
    "    chromeOptions.add_experimental_option(\"prefs\",{\"download.default_directory\":path})\n",
    "    driver = webdriver.Chrome(ChromeDriverManager().install(),options = chromeOptions)\n",
    "    driver.get(security_url)\n",
    "    \n",
    "    # to select Equity\n",
    "    equity = driver.find_element_by_xpath('//*[@id=\"ContentPlaceHolder1_ddSegment\"]')\n",
    "    equity = Select(equity)\n",
    "    equity.select_by_visible_text(\"Equity\")  \n",
    "\n",
    "    # to select Active\n",
    "    active = driver.find_element_by_xpath('//*[@id=\"ContentPlaceHolder1_ddlStatus\"]')\n",
    "    active = Select(active)\n",
    "    active.select_by_visible_text(\"Active\") \n",
    "    \n",
    "    # to click submit \n",
    "    submit = driver.find_element_by_xpath('//*[@id=\"ContentPlaceHolder1_btnSubmit\"]')\n",
    "    submit.send_keys(Keys.RETURN)\n",
    "\n",
    "    # to download csv file\n",
    "    driver.find_element_by_xpath(\"/html/body/div[1]/form/div[4]/div/div/div[2]/div/div/div[2]/a/i\").click()\n",
    "    time.sleep(3)\n",
    "    driver.quit()"
   ]
  },
  {
   "source": [
    "# Scraping of stock data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_stocks(security_id):\n",
    "    \"\"\"\n",
    "    Downloads the Stock data file.\n",
    "    \n",
    "    stock_url = \"https://www.bseindia.com/markets/equity/EQReports/StockPrcHistori.aspx?flag=0\"\n",
    "\n",
    "    creates the driver.\n",
    "\n",
    "    opens the stock_url.\n",
    "\n",
    "    sets the security id.\n",
    "\n",
    "    if file already exists\n",
    "\n",
    "        sets the from date by taking the last date from the file.\n",
    "        sets the to date.\n",
    "        downloads the file.\n",
    "\n",
    "    if file doesnt exists\n",
    "\n",
    "        sets the from date\n",
    "        sets the to date.\n",
    "        downloads the file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    security_id : string\n",
    "        security_id of the company\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    stock : dataframe\n",
    "\n",
    "    Methods:\n",
    "    --------\n",
    "    create_driver : creates the chrome driver.\n",
    "\n",
    "    set_to_date : Sets the TO date.\n",
    "\n",
    "    set_from_date : Sets the FROM date.\n",
    "\n",
    "    set_security_id : sets the security id.\n",
    "\n",
    "    download : downloads the file.\n",
    "\n",
    "    convert_date_to_unix_timestamp : Adds a new Unix Date column to the given dataframe.\n",
    "\n",
    "    \"\"\" \n",
    "\n",
    "    path = os.path.join(os.getcwd(),\"Data\\\\Stock\")\n",
    "    stock_url = \"https://www.bseindia.com/markets/equity/EQReports/StockPrcHistori.aspx?flag=0\"\n",
    "\n",
    "    def convert_date_to_unix_timestamp(stock_df):\n",
    "        \"\"\"\n",
    "        Adds a new Unix Date column to the given dataframe.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        stock_df : dataframe\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        stock_df : dataframe\n",
    "            updated dataframe with a new Unix Date column.\n",
    "        \"\"\"\n",
    "        stock_df[\"Unix Date\"] = stock_df[\"Date\"].apply(lambda x : time.mktime(x.timetuple()))\n",
    "        return stock_df\n",
    "\n",
    "    def set_from_date(d,m,y):\n",
    "        \"\"\"\n",
    "        Sets the FROM date.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        d : string\n",
    "            day\n",
    "\n",
    "        m : string \n",
    "            month\n",
    "\n",
    "        y : string\n",
    "            year \n",
    "\n",
    "        \"\"\"\n",
    "        from_date = driver.find_element_by_xpath('//*[@id=\"ContentPlaceHolder1_txtFromDate\"]')\n",
    "        from_date.clear()\n",
    "        from_date.click()\n",
    "        year = driver.find_element_by_xpath('/html/body/div[1]/div/div/select[2]') \n",
    "        year = Select(year)\n",
    "        while year.options[0].text > y:\n",
    "            year.select_by_visible_text(year.options[0].text) \n",
    "            year = driver.find_element_by_xpath('/html/body/div[1]/div/div/select[2]') \n",
    "            year = Select(year)\n",
    "\n",
    "        year.select_by_visible_text(y) \n",
    "\n",
    "        month = driver.find_element_by_xpath('/html/body/div[1]/div/div/select[1]') \n",
    "        month = Select(month)\n",
    "        month.select_by_visible_text(m)  \n",
    "\n",
    "        days=driver.find_element_by_xpath(\"//table/tbody/tr/td/a[text()=\"+str(d)+\"]\")\n",
    "        days.click()\n",
    "\n",
    "    def set_to_date(d,m,y):\n",
    "        \"\"\"\n",
    "        Sets the TO date.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        d : string\n",
    "            day\n",
    "\n",
    "        m : string \n",
    "            month\n",
    "\n",
    "        y : string\n",
    "            year \n",
    "\n",
    "        \"\"\"\n",
    "        to_date = driver.find_element_by_xpath('//*[@id=\"ContentPlaceHolder1_txtToDate\"]')\n",
    "        to_date.clear()\n",
    "        to_date.click()\n",
    "        year = driver.find_element_by_xpath('/html/body/div[1]/div/div/select[2]') \n",
    "        year = Select(year)\n",
    "        while year.options[0].text > y:\n",
    "            year.select_by_visible_text(year.options[0].text) \n",
    "            year = driver.find_element_by_xpath('/html/body/div[1]/div/div/select[2]') \n",
    "            year = Select(year)\n",
    "\n",
    "        year.select_by_visible_text(y) \n",
    "\n",
    "        month = driver.find_element_by_xpath('/html/body/div[1]/div/div/select[1]') \n",
    "        month = Select(month)\n",
    "        month.select_by_visible_text(m)  \n",
    "\n",
    "        days=driver.find_element_by_xpath(\"//table/tbody/tr/td/a[text()=\"+str(d)+\"]\")\n",
    "        days.click()\n",
    "    \n",
    "\n",
    "    def set_security_id(security):\n",
    "        \"\"\"\n",
    "        sets the secuirty id to the input field.\n",
    "\n",
    "        Parameters\n",
    "        -----------\n",
    "\n",
    "        security : string\n",
    "            security id of the company.\n",
    "\n",
    "        \"\"\"\n",
    "        element = driver.find_element_by_xpath('//*[@id=\"ContentPlaceHolder1_smartSearch\"]')\n",
    "        element.clear()\n",
    "        element.send_keys(security)\n",
    "        element.send_keys(Keys.ENTER)\n",
    "\n",
    "    def download():\n",
    "        \"\"\"\n",
    "        downloads the file.\n",
    "        \"\"\"\n",
    "        submit = driver.find_element_by_xpath('//*[@id=\"ContentPlaceHolder1_btnSubmit\"]')\n",
    "        submit.click()\n",
    "        time.sleep(1)\n",
    "        driver.find_element_by_xpath(\"/html/body/form/div[4]/div/div/div[1]/div/div[2]/div/div[1]/div[2]/span/a/i\").click()\n",
    "        time.sleep(3)\n",
    "        driver.quit()\n",
    "\n",
    "    def create_driver():\n",
    "        \"\"\"\n",
    "        Creates a Chrome Driver.\n",
    "\n",
    "        Returns\n",
    "        --------\n",
    "        driver : driver\n",
    "            chrome web driver.\n",
    "        \"\"\"\n",
    "        chromeOptions = webdriver.ChromeOptions()\n",
    "        # chromeOptions.add_argument(\"--headless\")\n",
    "        chromeOptions.add_experimental_option(\"prefs\",{\"download.default_directory\":path})\n",
    "        driver = webdriver.Chrome(ChromeDriverManager().install(), options = chromeOptions)\n",
    "        return driver\n",
    "\n",
    "    if os.path.exists(os.path.join(path,str(security_id)+\".csv\")):\n",
    "        driver = create_driver()\n",
    "        driver.get(stock_url)\n",
    "        old_df = pd.read_csv(os.path.join(path,str(security_id)+\".csv\"))\n",
    "        old_df[\"Date\"] = pd.to_datetime(old_df[\"Date\"])\n",
    "        last = old_df[\"Date\"].head(1)[0]\n",
    "        set_security_id(str(security_id))\n",
    "\n",
    "        set_from_date(last.day,calendar.month_abbr[last.month],str(last.year))\n",
    "        today = datetime.date.today()\n",
    "        # today = last+datetime.timedelta(365)\n",
    "        set_to_date(today.day,calendar.month_abbr[today.month],str(today.year))\n",
    "        download()\n",
    "        new_df = pd.read_csv(os.path.join(path,str(security_id)+\" (1).csv\"))\n",
    "        new_df[\"Date\"] = pd.to_datetime(new_df[\"Date\"],errors=\"coerce\")\n",
    "        new_df = new_df.drop(columns = [\"Unnamed: 13\"],axis=1,errors='ignore')\n",
    "        new_df = new_df.dropna(how='all')\n",
    "        new_df = convert_date_to_unix_timestamp(new_df)\n",
    "        res = new_df.append(old_df,ignore_index=True)\n",
    "        res.to_csv(os.path.join(path,str(security_id)+\".csv\"),index=None)\n",
    "        os.remove(os.path.join(path,str(security_id)+\" (1).csv\"))\n",
    "        new_df.to_csv(os.path.join(path,\"new\"+str(security_id)+\".csv\"),index=None)\n",
    "        return new_df\n",
    "    else:\n",
    "        driver = create_driver()\n",
    "        driver.get(stock_url)\n",
    "        set_security_id(str(security_id))\n",
    "        set_from_date(\"02\",\"Aug\",\"2007\")\n",
    "        today = datetime.date.today()\n",
    "        # start = datetime.datetime.strptime(\"01 Jan 2000\",\"%d %b %Y\")\n",
    "        # today = start+datetime.timedelta(365)\n",
    "        set_to_date(today.day,calendar.month_abbr[today.month],str(today.year))\n",
    "        download()\n",
    "        stock =  pd.read_csv(os.path.join(path,str(security_id)+\".csv\"))\n",
    "        stock.Date = pd.to_datetime(stock.Date,errors=\"coerce\")\n",
    "        stock = stock.drop(columns = [\"Unnamed: 13\"],axis=1,errors='ignore')\n",
    "        stock = stock.dropna(how='all')\n",
    "        stock = convert_date_to_unix_timestamp(stock)\n",
    "        stock.to_csv(os.path.join(path,str(security_id)+\".csv\"),index=None)\n",
    "        return stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[WDM] - ====== WebDriver manager ======\n",
      "[WDM] - Current google-chrome version is 90.0.4430\n",
      "[WDM] - Get LATEST driver version for 90.0.4430\n",
      "\n",
      "\n",
      "[WDM] - There is no [win32] chromedriver for browser 90.0.4430 in cache\n",
      "[WDM] - Get LATEST driver version for 90.0.4430\n",
      "[WDM] - Trying to download new driver from https://chromedriver.storage.googleapis.com/90.0.4430.24/chromedriver_win32.zip\n",
      "[WDM] - Driver has been saved in cache [C:\\Users\\VenkataSaiKrishna\\.wdm\\drivers\\chromedriver\\win32\\90.0.4430.24]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'f:\\\\PracticumProject\\\\stock-analysis-tool\\\\Data\\\\Stock\\\\500002 (1).csv'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-fb4eed05bf74>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdownload_stocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"500002\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-5-924d29d5e3d9>\u001b[0m in \u001b[0;36mdownload_stocks\u001b[1;34m(security_id)\u001b[0m\n\u001b[0;32m    193\u001b[0m         \u001b[0mset_to_date\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoday\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mday\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcalendar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmonth_abbr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtoday\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmonth\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoday\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myear\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m         \u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 195\u001b[1;33m         \u001b[0mnew_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msecurity_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\" (1).csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m         \u001b[0mnew_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Date\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Date\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"coerce\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m         \u001b[0mnew_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"Unnamed: 13\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ignore'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1048\u001b[0m             )\n\u001b[0;32m   1049\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1050\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1051\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1866\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1867\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1868\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1869\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"encoding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m         \"\"\"\n\u001b[1;32m-> 1362\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"replace\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 642\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'f:\\\\PracticumProject\\\\stock-analysis-tool\\\\Data\\\\Stock\\\\500002 (1).csv'"
     ]
    }
   ],
   "source": [
    "download_stocks(\"500002\")"
   ]
  },
  {
   "source": [
    "# Scraping of Corporate Actions Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_corporate_actions(security_id):\n",
    "\n",
    "    \"\"\"\n",
    "    Downloads the corporate actions of the give security id.\n",
    "\n",
    "    corporate_url = \"https://www.bseindia.com/corporates/corporate_act.aspx\"\n",
    "\n",
    "    creates the driver.\n",
    "    opens the corporate_url.\n",
    "    sets the from date.\n",
    "    sets the to date.\n",
    "    downloads the file.\n",
    "    replaces the if already downloaded.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    security_id : string\n",
    "        security id of the company.\n",
    "\n",
    "    Methods:\n",
    "    --------\n",
    "    create_driver : creates the chrome driver.\n",
    "\n",
    "    set_security_id : sets the security id.\n",
    "    \n",
    "    set_to_date : Sets the TO date.\n",
    "\n",
    "    set_from_date : Sets the FROM date.\n",
    "\n",
    "    download : downloads the file.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    path = os.path.join(os.getcwd(),\"Data\\\\CorporateActions\")\n",
    "    corporate_url = \"https://www.bseindia.com/corporates/corporate_act.aspx\"\n",
    "\n",
    "    def set_from_date(d,m,y):\n",
    "        \"\"\"\n",
    "        Sets the FROM date.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        d : string\n",
    "            day\n",
    "\n",
    "        m : string \n",
    "            month\n",
    "\n",
    "        y : string\n",
    "            year \n",
    "\n",
    "        \"\"\"\n",
    "        from_date = driver.find_element_by_xpath('//*[@id=\"ContentPlaceHolder1_txtDate\"]')\n",
    "        from_date.clear()\n",
    "        from_date.click()\n",
    "        year = driver.find_element_by_xpath('/html/body/div[2]/div/div/select[2]') \n",
    "        year = Select(year)\n",
    "        while year.options[0].text > y:\n",
    "            year.select_by_visible_text(year.options[0].text) \n",
    "            year = driver.find_element_by_xpath('/html/body/div[2]/div/div/select[2]') \n",
    "            year = Select(year)\n",
    "\n",
    "        year.select_by_visible_text(y) \n",
    "\n",
    "        month = driver.find_element_by_xpath('/html/body/div[2]/div/div/select[1]') \n",
    "        month = Select(month)\n",
    "        month.select_by_visible_text(m)  \n",
    "\n",
    "        days=driver.find_element_by_xpath(\"//table/tbody/tr/td/a[text()=\"+str(d)+\"]\")\n",
    "        days.click()\n",
    "\n",
    "    def set_to_date(d,m,y):\n",
    "        \"\"\"\n",
    "        Sets the TO date.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        d : string\n",
    "            day\n",
    "\n",
    "        m : string \n",
    "            month\n",
    "\n",
    "        y : string\n",
    "            year \n",
    "\n",
    "        \"\"\"\n",
    "        to_date = driver.find_element_by_xpath('//*[@id=\"ContentPlaceHolder1_txtTodate\"]')\n",
    "        to_date.clear()\n",
    "        to_date.click()\n",
    "        year = driver.find_element_by_xpath('/html/body/div[2]/div/div/select[2]') \n",
    "        year = Select(year)\n",
    "        while year.options[0].text > y:\n",
    "            print(year.options[0].text,y)\n",
    "            year.select_by_visible_text(year.options[0].text) \n",
    "            year = driver.find_element_by_xpath('/html/body/div[2]/div/div/select[2]') \n",
    "            year = Select(year)\n",
    "\n",
    "        year.select_by_visible_text(y) \n",
    "\n",
    "        month = driver.find_element_by_xpath('/html/body/div[2]/div/div/select[1]') \n",
    "        month = Select(month)\n",
    "        month.select_by_visible_text(m)  \n",
    "\n",
    "        days=driver.find_element_by_xpath(\"//table/tbody/tr/td/a[text()=\"+str(d)+\"]\")\n",
    "        days.click()\n",
    "\n",
    "    def set_security_id(security):\n",
    "        \"\"\"\n",
    "        sets the secuirty id to the input field.\n",
    "\n",
    "        Parameters\n",
    "        -----------\n",
    "\n",
    "        security : string\n",
    "            security id of the company.\n",
    "\n",
    "        \"\"\"\n",
    "        element = driver.find_element_by_xpath('//*[@id=\"ContentPlaceHolder1_SmartSearch_smartSearch\"]')\n",
    "        element.clear()\n",
    "        element.send_keys(security)\n",
    "        element.send_keys(Keys.ENTER)\n",
    "    \n",
    "\n",
    "    def download():\n",
    "        \"\"\"\n",
    "        downloads the file.\n",
    "        \"\"\"\n",
    "        submit = driver.find_element_by_xpath('//*[@id=\"ContentPlaceHolder1_btnSubmit\"]')\n",
    "        submit.click()\n",
    "        time.sleep(1)\n",
    "        driver.find_element_by_xpath(\"/html/body/div[1]/form/div[4]/div/div/div[2]/div/div/div[2]/a/i\").click()\n",
    "        time.sleep(4)\n",
    "        driver.quit()\n",
    "\n",
    "    def create_driver():\n",
    "        \"\"\"\n",
    "        Creates a Chrome Driver.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        driver : driver\n",
    "            chrome web driver.\n",
    "        \"\"\"\n",
    "        chromeOptions = webdriver.ChromeOptions()\n",
    "        # chromeOptions.add_argument(\"--headless\")\n",
    "        chromeOptions.add_experimental_option(\"prefs\",{\"download.default_directory\":path})\n",
    "        driver = webdriver.Chrome(ChromeDriverManager().install(), options = chromeOptions)\n",
    "        return driver\n",
    "\n",
    "    driver = create_driver()\n",
    "    driver.get(corporate_url)\n",
    "    set_security_id(str(security_id))\n",
    "    # set_from_date(\"01\",\"Jan\",\"1991\")\n",
    "    set_from_date(\"02\",\"Aug\",\"2007\")\n",
    "    today = datetime.date.today()\n",
    "    set_to_date(today.day,calendar.month_abbr[today.month],str(today.year))\n",
    "    download()\n",
    "    if os.path.exists(os.path.join(path,str(security_id)+\".csv\")):\n",
    "        os.remove(os.path.join(path,str(security_id)+\".csv\"))\n",
    "    os.rename(os.path.join(path,\"Corporate_Actions.csv\"),os.path.join(path,str(security_id)+\".csv\"))\n",
    "    "
   ]
  },
  {
   "source": [
    "# Scraping of Index Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_index():\n",
    "\n",
    "    \"\"\"\n",
    "    Downloads the index data file.\n",
    "\n",
    "    index_url = \"https://www.bseindia.com/indices/IndexArchiveData.html\"\n",
    "    index = \"S&P BSE 500\"\n",
    "\n",
    "    creates the driver.\n",
    "\n",
    "    opens the index_url.\n",
    "\n",
    "    sets the index.\n",
    "\n",
    "    if file already exists\n",
    "\n",
    "        sets the from date by taking the last date from the file.\n",
    "        sets the to date.\n",
    "        downloads the file.\n",
    "        renames the file to Index.csv\n",
    "\n",
    "    if file doesnt exists\n",
    "\n",
    "        sets the from date\n",
    "        sets the to date.\n",
    "        downloads the file.\n",
    "        renames the file to Index.csv\n",
    "\n",
    "    Methods:\n",
    "    --------\n",
    "    create_driver : creates the chrome driver.\n",
    "\n",
    "    set_to_date : Sets the TO date.\n",
    "\n",
    "    set_from_date : Sets the FROM date.\n",
    "\n",
    "    set_index : sets the index.\n",
    "\n",
    "    download : downloads the file.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    index_url = \"https://www.bseindia.com/indices/IndexArchiveData.html\"\n",
    "    index = \"S&P BSE 500\"\n",
    "    path = os.path.join(os.getcwd(),\"Data\")\n",
    "\n",
    "    def set_from_date(d,m,y):\n",
    "        \"\"\"\n",
    "        Sets the FROM date.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        d : string\n",
    "            day\n",
    "\n",
    "        m : string \n",
    "            month\n",
    "\n",
    "        y : string\n",
    "            year \n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        from_date = driver.find_element_by_xpath('//*[@id=\"txtFromDt\"]')\n",
    "        from_date.clear()\n",
    "        from_date.click()\n",
    "        year = driver.find_element_by_xpath('/html/body/div[4]/div/div/select[2]') \n",
    "        year = Select(year)\n",
    "        while year.options[0].text > y:\n",
    "            year.select_by_visible_text(year.options[0].text) \n",
    "            year = driver.find_element_by_xpath('/html/body/div[4]/div/div/select[2]') \n",
    "            year = Select(year)\n",
    "\n",
    "        year.select_by_visible_text(y) \n",
    "\n",
    "        month = driver.find_element_by_xpath('/html/body/div[4]/div/div/select[1]') \n",
    "        month = Select(month)\n",
    "        month.select_by_visible_text(m)  \n",
    "\n",
    "        days=driver.find_element_by_xpath(\"//table/tbody/tr/td/a[text()=\"+str(d)+\"]\")\n",
    "        days.click()\n",
    "\n",
    "    def set_to_date(d,m,y):\n",
    "        \"\"\"\n",
    "        Sets the TO date.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        d : string\n",
    "            day\n",
    "\n",
    "        m : string \n",
    "            month\n",
    "\n",
    "        y : string\n",
    "            year \n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        to_date = driver.find_element_by_xpath('//*[@id=\"txtToDt\"]')\n",
    "        to_date.clear()\n",
    "        to_date.click()\n",
    "        year = driver.find_element_by_xpath('/html/body/div[4]/div/div/select[2]') \n",
    "        year = Select(year)\n",
    "        while year.options[0].text > y:\n",
    "            print(year.options[0].text,y)\n",
    "            year.select_by_visible_text(year.options[0].text) \n",
    "            year = driver.find_element_by_xpath('/html/body/div[4]/div/div/select[2]') \n",
    "            year = Select(year)\n",
    "\n",
    "        year.select_by_visible_text(y) \n",
    "\n",
    "        month = driver.find_element_by_xpath('/html/body/div[4]/div/div/select[1]') \n",
    "        month = Select(month)\n",
    "        month.select_by_visible_text(m)  \n",
    "\n",
    "        days=driver.find_element_by_xpath(\"//table/tbody/tr/td/a[text()=\"+str(d)+\"]\")\n",
    "        days.click()\n",
    "\n",
    "\n",
    "    def set_index(index_):\n",
    "        \"\"\"\n",
    "        Sets the index field.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        index_ : string\n",
    "            index value\n",
    "        \"\"\"\n",
    "\n",
    "        indexes = driver.find_element_by_xpath('//*[@id=\"ddlIndex\"]')\n",
    "        indexes = Select(indexes)\n",
    "        indexes.select_by_visible_text(index_)  \n",
    "\n",
    "    def download():\n",
    "        \"\"\"\n",
    "        downloads the file.\n",
    "        \"\"\"\n",
    "        submit = driver.find_element_by_xpath('/html/body/div[2]/div/div[2]/div[5]/div/input')\n",
    "        submit.click()\n",
    "        time.sleep(1)\n",
    "        driver.find_element_by_xpath(\"/html/body/div[2]/div/div[1]/div/div[1]/div[2]/i\").click()\n",
    "        time.sleep(3)\n",
    "        driver.quit()\n",
    "\n",
    "    def create_driver():\n",
    "        \"\"\"\n",
    "        Creates a Chrome Driver.\n",
    "\n",
    "        Returns\n",
    "        --------\n",
    "        driver : driver\n",
    "            chrome web driver.\n",
    "        \"\"\"\n",
    "        chromeOptions = webdriver.ChromeOptions()\n",
    "        chromeOptions.add_argument(\"--headless\")\n",
    "        chromeOptions.add_experimental_option(\"prefs\",{\"download.default_directory\":path})\n",
    "        driver = webdriver.Chrome(ChromeDriverManager().install(), options = chromeOptions)\n",
    "        return driver\n",
    "\n",
    "    driver = create_driver()\n",
    "    driver.get(index_url)\n",
    "    set_index(\"S&P BSE 500\")\n",
    "    set_from_date(\"2\",\"Aug\",\"2007\")\n",
    "    today = datetime.date.today()\n",
    "    set_to_date(today.day,calendar.month_abbr[today.month],str(today.year))\n",
    "    download()\n",
    "    res = pd.read_csv(os.path.join(path,\"CSVForDate.csv\"),names=[\"Date\",\"Open\",\"High\",\"Low\",\"Close\"])\n",
    "    res = res.iloc[1:]\n",
    "    res[\"Date\"] = pd.to_datetime(res[\"Date\"])\n",
    "    os.remove(os.path.join(path,\"CSVForDate.csv\"))\n",
    "    res.to_csv(os.path.join(path,\"Index.csv\"),index=None)"
   ]
  },
  {
   "source": [
    "# Scraping Risk Free Rate Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def download_risk_free_rate():\n",
    "    \"\"\"\n",
    "    Downloads the Risk Free Rate file.\n",
    "\n",
    "    risk_free_rate_url = \"https://www.treasury.gov/resource-center/data-chart-center/interest-rates/pages/textview.aspx?data=yield\"\n",
    "\n",
    "    creates the driver.\n",
    "    opens the risk_free_rate_url.\n",
    "    downloads the file.\n",
    "\n",
    "    Methods:\n",
    "    --------\n",
    "\n",
    "    create_driver : creates the chrome driver.\n",
    "\n",
    "    download : extracts the data from the page and saves to a csv file.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    path = os.path.join(os.getcwd(),\"Data\")\n",
    "    risk_free_rate_url = \"https://www.treasury.gov/resource-center/data-chart-center/interest-rates/pages/textview.aspx?data=yield\"\n",
    "\n",
    "    def create_driver():\n",
    "        \"\"\"\n",
    "        Creates a Chrome Driver.\n",
    "\n",
    "        Returns\n",
    "        --------\n",
    "        driver : driver\n",
    "            chrome web driver.\n",
    "        \"\"\"\n",
    "        chromeOptions = webdriver.ChromeOptions()\n",
    "        chromeOptions.add_argument(\"--headless\")\n",
    "        chromeOptions.add_experimental_option(\"prefs\",{\"download.default_directory\":path})\n",
    "        driver = webdriver.Chrome(ChromeDriverManager().install(), options = chromeOptions)\n",
    "        return driver\n",
    "\n",
    "    def download():\n",
    "        \"\"\"\n",
    "        downloads the file.\n",
    "        \"\"\"\n",
    "        \n",
    "        ele = driver.find_element_by_xpath('//*[@id=\"interestRateTimePeriod\"]')\n",
    "        ele = Select(ele)\n",
    "        ele.select_by_visible_text(\"All\") \n",
    "\n",
    "        btn = driver.find_element_by_xpath('/html/body/form/div[8]/div/div[1]/div/div[2]/div/div/div/div[1]/div[2]/div/table/tbody/tr/td/div/div[3]/div[2]/input')\n",
    "        btn.click()\n",
    "        time.sleep(15)\n",
    "        soup = BeautifulSoup(driver.page_source,'html')\n",
    "        driver.quit()\n",
    "        table = soup.find_all(\"table\", {\"class\": \"t-chart\"})\n",
    "        risk_free_rate = pd.read_html(str(table))[0]\n",
    "        risk_free[\"Date\"] = pd.to_datetime(risk_free[\"Date\"])\n",
    "        risk_free_rate.to_csv(os.path.join(path,\"inRiskFreeRate.csv\"),index=None)\n",
    "        risk_free = risk_free_rate[[\"Date\",\"3 mo\"]]\n",
    "        risk_free_rate[\"Rate\"] = risk_free_rate[\"3 mo\"]\n",
    "        risk_free.columns = [\"Date\",\"Rate\"]\n",
    "        risk_free[\"Date\"] = pd.to_datetime(risk_free[\"Date\"])\n",
    "        risk_free.dropna(inplace=True)\n",
    "        risk_free.to_csv(os.path.join(path,\"RiskFreeRate.csv\"),index=None)\n",
    "    driver = create_driver()\n",
    "    driver.get(risk_free_rate_url)\n",
    "    download()"
   ]
  },
  {
   "source": [
    "# Scraping of Revenue Profit Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_revenue_profit(code,name): \n",
    "    \"\"\"\n",
    "    Creates the revenue profit file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    code : string\n",
    "        security code of the company.\n",
    "    name : \n",
    "        security id of the company.\n",
    "\n",
    "    Methods:\n",
    "    --------\n",
    "\n",
    "    create_driver : creates the chrome driver.\n",
    "\n",
    "    download : extracts the data from the page and saves to a csv file.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    path = os.path.join(os.getcwd(),\"Data\\\\Revenue\")\n",
    "\n",
    "    def create_driver():\n",
    "        \"\"\"\n",
    "        Creates a Chrome Driver.\n",
    "\n",
    "        Returns\n",
    "        --------\n",
    "        driver : driver\n",
    "            chrome web driver.\n",
    "        \"\"\"\n",
    "        chromeOptions = webdriver.ChromeOptions()\n",
    "        # chromeOptions.add_argument(\"--headless\")\n",
    "        chromeOptions.add_experimental_option(\"prefs\",{\"download.default_directory\":path})\n",
    "        driver = webdriver.Chrome(ChromeDriverManager().install(), options = chromeOptions)\n",
    "        return driver\n",
    "\n",
    "    def download():\n",
    "        \"\"\"\n",
    "        downloads the file.\n",
    "        \"\"\"\n",
    "        columns = [\"security code\",\"security name\",'revenue','income','expenditure','profit','eps',\"year\",\"quartile\"]\n",
    "        code_df = pd.DataFrame(columns=columns)\n",
    "        for q in range(55,108):\n",
    "            url = \"https://www.bseindia.com/corporates/results.aspx?Code=\" + str(code) +\"&Company=\"+ str(name) +\"&qtr=\"+ str(q) +\"&RType=D\"\n",
    "            driver.get(url)\n",
    "            html = driver.page_source\n",
    "            soup = BeautifulSoup(html, \"html\")\n",
    "\n",
    "            table = soup.find_all(\"table\",attrs={\"id\":\"ContentPlaceHolder1_tbl_typeID\"})\n",
    "            table = pd.read_html(str(table))[0]\n",
    "            table = table[[0,1]]\n",
    "            table.dropna(inplace=True)\n",
    "            table = table.transpose()\n",
    "            table.columns = table.iloc[0]\n",
    "            table = table[1:]\n",
    "            table.columns = map(str.lower, table.columns)\n",
    "            table.drop([\"description\"],inplace=True,axis=1)\n",
    "            try:\n",
    "                table[\"date begin\"] = pd.to_datetime(table[\"date begin\"])\n",
    "                date = table.iloc[0][\"date begin\"]\n",
    "                table[\"quartile\"] =  (date.month-1)//3 + 1\n",
    "                table[\"year\"] = date.year\n",
    "                table[\"security name\"] = name\n",
    "                table[\"security code\"] = code\n",
    "                cols = table.columns\n",
    "                mycols = ['revenue','income','expenditure','profit','eps']\n",
    "                row = {}\n",
    "                row[\"security name\"] = name\n",
    "                row[\"security code\"] = code\n",
    "                row[\"year\"] = date.year\n",
    "                row[\"quartile\"] = (date.month-1)//3 + 1\n",
    "                for my in mycols:\n",
    "                    try:\n",
    "                        res = [c for c in cols if my in c]\n",
    "                        if my == \"income\":\n",
    "                            p = [c for c in res if \"total income\" == c ] \n",
    "                            res = p or res\n",
    "                        elif my == \"profit\":\n",
    "                            p = [c for c in res if \"net profit\" == c]\n",
    "                            res = p or res\n",
    "                        elif my == \"expenditure\":\n",
    "                            p = [c for c in cols if \"expenses\" in c]\n",
    "                            res = p or res\n",
    "                        elif my ==\"eps\":\n",
    "                            a = \"Basic for discontinued & continuing operation\"\n",
    "                            b = \"Diluted for discontinued & continuing operation\"\n",
    "                            p = [c for c in cols if a.lower() in c or b.lower() in c]\n",
    "                            res = p or res\n",
    "                        elif my == \"revenue\":\n",
    "                            p = [c for c in cols if \"sales\" in c]\n",
    "                            res = p or res\n",
    "                            # row[\"revenue\"] = table[res].values[0][0]\n",
    "                            # continue\n",
    "                            pass\n",
    "                        row[my] = table[res].values[0][0]\n",
    "                    except :\n",
    "                        row[my] = \"\"\n",
    "                        traceback.print_exc()\n",
    "                code_df = code_df.append(row,ignore_index=True)\n",
    "            except Exception as e:\n",
    "                traceback.print_exc()\n",
    "        code_df.to_csv(os.path.join(path,str(code)+\".csv\"),index=None)\n",
    "    driver = create_driver()\n",
    "    download()\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my = pd.read_csv(\"my.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_risk_free_rate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for _,row in my.iterrows():\n",
    "    try:\n",
    "        security_id = row[\"Security Code\"]\n",
    "        name = row[\"Security Id\"]\n",
    "        print(security_id,name)\n",
    "        download_stocks(security_id)\n",
    "        download_revenue_profit(security_id,name)\n",
    "        download_corporate_actions(security_id)\n",
    "    except Exception as e:\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}