{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["import pandas as pd\n","import numpy as np \n","import os\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LinearRegression\n","from sklearn import metrics\n","from math import sqrt\n","import statsmodels.api as sm\n","from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n","from sklearn.model_selection import GridSearchCV\n","import time \n","import matplotlib\n","import matplotlib.pyplot as plt\n","import matplotlib.cm as cmx\n","import matplotlib.colors as colors\n","import matplotlib.patches as patches\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.feature_selection import f_classif\n","from sklearn.metrics import confusion_matrix\n","import math\n","from sklearn.metrics import roc_curve\n","from sklearn.metrics import roc_auc_score\n","import traceback\n","import prettytable\n","import io"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["import warnings; warnings.simplefilter('ignore')"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["path = \"/kaggle/input/stockdata\"\n","path"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["# PreProcessing Data    "]},{"metadata":{"trusted":true},"cell_type":"code","source":["def pre_process_data(data,null_threshold):\n","    \"\"\"\n","    Drops Date and Unix Date columns from the data.\n","    Drops the columns which has null values more than specified null_threshold.\n","    Replaces infinite values with NAN.\n","    Drops the rows which has null values.\n","\n","    Parameters\n","    ----------\n","    data : dataframe\n","\n","    null_threshold : numeric\n","        numeric value describing the amount of null values that can be present.\n","\n","    Returns\n","    -------\n","    data : dataframe\n","        an updated dataframe after performing all the opertaions.\n","    \"\"\"\n","    \n","    data.drop(columns=['Unix Date','Date'],axis=1,inplace=True)\n","    total = data.shape[0]\n","    for col in data.columns:\n","        if null_threshold * total / 100 < data[col].isnull().sum():\n","            data.drop(columns=[col],axis=1,inplace=True)\n","    data.replace([np.inf, -np.inf], np.nan, inplace=True)\n","    data.dropna(axis=0,inplace=True)\n","    return data"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["# Removing columns based on dependent column\n"]},{"metadata":{"trusted":true},"cell_type":"code","source":["def dependent_column(data,column):\n","    \"\"\"\n","    Removes all the Next Day columns.\n","    Removes all the non Growth Rate Columns (GR)\n","    add the predictor column to list of columns.\n","\n","    Parameters\n","    ----------\n","    data : dataframe\n","\n","    column : string\n","        name of the predictor column \n","\n","    Returns\n","    -------\n","    data : dataframe\n","        an updated dataframe after performing all the opertaions.\n","    column : string\n","        name of the predictor column\n","    \"\"\"\n","    cols = [col for col in data.columns if \"next\" not in col.lower() and col.lower().endswith(\"gr\")]\n","    cols.append(column)\n","    data = data[cols]\n","    return (data,column)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["# Parameters Tuning"]},{"metadata":{"trusted":true},"cell_type":"code","source":["def parameters_tuning(penalty,C,X_train, y_train):\n","    logistic = LogisticRegression()\n","    hyperparameters = dict(C=C, penalty=penalty)\n","    try:\n","        clf = GridSearchCV(logistic, hyperparameters, cv=5, verbose=0)\n","        best_model = clf.fit(X_train, y_train)\n","    except:\n","        hyperparameters[\"penalty\"] = ['none','l2']\n","        clf = GridSearchCV(logistic, hyperparameters, cv=5, verbose=0)\n","        best_model = clf.fit(X_train, y_train)\n","    penalty = best_model.best_estimator_.get_params()[\"penalty\"]\n","    C = best_model.best_estimator_.get_params()[\"C\"]\n","    return (penalty,C)\n"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["# OLS Regression"]},{"metadata":{"trusted":true},"cell_type":"code","source":["def OLS_Regression(X_train,Y_train):\n","    X_train = np.array(X_train, dtype=float)\n","    ols_model = sm.OLS(Y_train, X_train).fit()\n","    rsquared_adj = ols_model.rsquared_adj\n","    aic = ols_model.aic\n","    bic = ols_model.bic\n","    fvalue = ols_model.fvalue\n","    return {\"rsquared_adj\":rsquared_adj,\"aic\":aic,\"bic\":bic,\"fvalue\":fvalue}"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["# Confusion Matrix\n","\n","### true negatives  {0,0},\n","### false negatives {1,0},\n","### true positives  {1,1},\n","### false positives {0,1}."]},{"metadata":{"trusted":true},"cell_type":"code","source":["def create_confusion_matrix(y_pred,y_true):\n","    \n","    cm = confusion_matrix(y_true,y_pred)\n","    accuracy = metrics.accuracy_score(y_true,y_pred)\n","    precision = metrics.precision_score(y_true,y_pred)\n","    recall = metrics.recall_score(y_true,y_pred)\n","    f1_score = metrics.f1_score(y_true,y_pred)\n","    return {\"accuracy\":accuracy,\"precision\":precision,\"recall\":recall,\"f1_score\":f1_score,\"confusion matrix\":cm}\n","\n","    # accuracy = float(cm.diagonal().sum())/len(y_test)\n","    # TN = cm[0][0]\n","    # FP = cm[0][1]\n","    # FN = cm[1][0]\n","    # TP = cm[1][1]\n","    \n","    # precision1 = TP / (TP + FP)\n","    # precision1 = 0 if math.isnan(precision1) else precision1\n","    \n","    # recall1 = TP / (TP + FN)\n","    # recall1 = 0 if math.isnan(recall1) else recall1\n","\n","    # f_measure = (2 * precision1 * recall1)/(precision1 + recall1)\n","    \n","    # precision0 = TN / (TN + FN)\n","    # precision0 = 0 if math.isnan(precision0) else precision0\n","    \n","    # recall0 = TN / (FP  + TN)\n","    # recall0 = 0 if math.isnan(recall0) else recall0\n"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["# Logistic Regression"]},{"metadata":{"trusted":true},"cell_type":"code","source":["def logistic_regression(df,threshold):\n","    df[\"Target\"] = df[\"Next Day Close Price GR\"].apply(lambda x : 1 if x >= threshold else 0)\n","    X = df[df.columns[:-2]]\n","    Y = df[\"Target\"]\n","    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=0)\n","    penalty = ['l1', 'l2','none']\n","    C = [0.001,0.01,0.1,1,10,100]\n","    penalty,C = parameters_tuning(penalty,C,X_train, y_train)\n","    logmodel = LogisticRegression(penalty = penalty, C = C,random_state = 0)\n","    logmodel.fit(X_train, y_train)\n","    y_pred = logmodel.predict(X_test)\n","\n","    confidence = logmodel.score(X_test, y_test)\n","    rmse = sqrt(metrics.mean_squared_error(y_test, y_pred))\n","    mae = metrics.mean_absolute_error(y_test, y_pred)\n","    mse = metrics.mean_squared_error(y_test, y_pred)\n","    confusion_mat =  create_confusion_matrix(y_pred,y_test)\n","    ols_values = OLS_Regression(X_train,y_train)\n","    myres = {\"root_mean_squared_error\":rmse,\"mean_absolute_error\":mae,\"mean_squared_error\":mse,\"confidence\":confidence}\n","    myres.update(confusion_mat)\n","    myres.update({\"f-value\":ols_values[\"fvalue\"]})\n","    return myres"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["top = pd.read_csv(os.path.join(path,\"top.csv\"))\n","top"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["outputpath = os.getcwd()\n","outputpath"],"execution_count":null,"outputs":[]},{"metadata":{"tags":[],"trusted":true},"cell_type":"code","source":["%%time\n","df_cols = ['features', 'threshold', 'pvalue', 'fvalue','root_mean_squared_error','mean_absolute_error', 'mean_squared_error', 'confidence', 'accuracy',\n","       'precision', 'recall', 'f1_score', 'f-value',\"confusion matrix\"]\n","for _,row in top.iterrows():\n","    stock_result = pd.DataFrame(columns=df_cols)\n","    name = row['security id']\n","    company = {}\n","    df = pd.read_csv(os.path.join(path,\"Data/Stock/\"+\"gr\"+str(name)+\".csv\"))\n","    df = pre_process_data(df,60)\n","    column = \"Next Day Close Price GR\"\n","    (df,column) = dependent_column(df,column)\n","\n","    threshold_values = [0.01,0.02,0.03,0.04,0.05,0.06,0.07,0.08,0.09,0.1]\n","    for threshold in threshold_values:\n","        try:\n","            target = df[\"Next Day Close Price GR\"].apply(lambda x : 1 if x >= threshold else 0)\n","            X = df[df.columns[:-2]]\n","            Y = target\n","            fvalues, pvalues = f_classif(X,Y)\n","            fvalues = dict(zip(X.columns,fvalues))\n","            pvalues = dict(zip(X.columns,pvalues))\n","            dataset = []\n","            p_range = [0.05,0.1,0.15,0.2,0.25]\n","            for p in p_range:\n","                mycols = list()\n","                for col,val in pvalues.items():\n","                    if val <= p:\n","                        mycols.append(col)\n","                if mycols == []:\n","                    res = {\"features\":mycols,\"threshold\":threshold,\"pvalue\":p}\n","                    dataset.append(res)\n","                    continue\n","                res = logistic_regression(df[mycols+[column]],threshold)\n","                fsol = [b for a,b in fvalues.items() if a in mycols]\n","                rf = np.max(fsol)\n","                res.update({\"features\":mycols,\"threshold\":threshold,\"pvalue\":p,\"fvalue\":rf})\n","                dataset.append(res)\n","\n","            f_range = [0.1,0.5,1,2,5,10,100]\n","            for f in f_range:\n","                mycols = list()\n","                for col,val in fvalues.items():\n","                    if val >= f:\n","                        mycols.append(col)\n","\n","                if mycols == []:\n","                    res = {\"features\":mycols,\"threshold\":threshold,\"fvalue\":f}\n","                    dataset.append(res)\n","                    continue\n","                res = logistic_regression(df[mycols+[column]],threshold)\n","                psol = [b for a,b in pvalues.items() if a in mycols]\n","                rp = np.max(psol)\n","                res.update({\"features\":mycols,\"threshold\":threshold,\"fvalue\":f,\"pvalue\":rp})\n","                dataset.append(res)\n","        except Exception as e:\n","            traceback.print_exc()\n","        res_df = pd.DataFrame(dataset)\n","        stock_result = stock_result.append(res_df,ignore_index=True)\n","    stock_result.to_csv(os.path.join(outputpath,str(name)+\"_logistic\"+\".csv\"),index=None,float_format=\"%.6f\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","import pandas as pd\n","import prettytable"]},{"metadata":{"trusted":true},"cell_type":"code","source":["path = os.path.join(os.getcwd(),\"Results\")\n","path"],"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["best_bpnn = pd.DataFrame()\n","for filename in os.listdir(path):\n","    if filename.endswith(\"_logistic.csv\"):\n","        df = pd.read_csv(os.path.join(path,filename))\n","        columns = ['threshold', 'pvalue', 'fvalue','accuracy', 'precision', 'recall', 'f1_score','confusion matrix']\n","        df = df[columns]\n","        table = prettytable.PrettyTable()\n","        table.field_names = columns\n","        table.title = str(filename[:6]) + \" logistic classification\"\n","        for _,row in df.iterrows():\n","            row = [round(r,6) if isinstance(r,(float,int)) else r for r in row]\n","            table.add_row(row)\n","        print(table)\n","        df[\"security id\"] = filename[:6]\n","        for name, log in df.groupby(by=[\"threshold\"]):\n","            log = log.sort_values(by=[\"f1_score\"],ascending=[False])\n","            # cols = log.columns.tolist()\n","            # log = log[[cols[-1]]+cols[:-1]]\n","            best_bpnn = best_bpnn.append(log.head(1),ignore_index=True)\n","# best_bpnn.to_csv(os.path.join(path,\"_best_logistic\"+\".csv\"),index=None)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["best_bpnn"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for name in os.listdir(path):\n","    if name.endswith(\"_logistic.csv\"):\n","        df = pd.read_csv(os.path.join(path,name))\n","        display(df)\n","        break"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.8.3-final","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}