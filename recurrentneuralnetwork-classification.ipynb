{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["import os\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import GridSearchCV\n","from sklearn import metrics\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import LSTM\n","from keras.layers import Dropout\n","from keras.backend import sigmoid\n","from sklearn.metrics import confusion_matrix\n","from keras.wrappers.scikit_learn import KerasClassifier\n","import matplotlib.pyplot as plt\n","from math import sqrt\n","import threading\n","from multiprocessing.pool import ThreadPool\n","import time\n","import multiprocessing\n","import traceback\n","\n","import prettytable"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["import warnings; warnings.simplefilter('ignore')"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["def pre_process_data(data,null_threshold):\n","    \"\"\"\n","    Drops Date and Unix Date columns from the data.\n","    Drops the columns which has null values more than specified null_threshold.\n","    Replaces infinite values with NAN.\n","    Drops the rows which has null values.\n","\n","    Parameters\n","    ----------\n","    data : dataframe\n","\n","    null_threshold : numeric\n","        numeric value describing the amount of null values that can be present.\n","\n","    Returns\n","    -------\n","    data : dataframe\n","        an updated dataframe after performing all the opertaions.\n","    \"\"\"\n","    \n","    data.drop(columns=['Unix Date','Date'],axis=1,inplace=True)\n","    total = data.shape[0]\n","    for col in data.columns:\n","        if null_threshold * total / 100 < data[col].isnull().sum():\n","            data.drop(columns=[col],axis=1,inplace=True)\n","    data.replace([np.inf, -np.inf], np.nan, inplace=True)\n","    data = data.apply(pd.to_numeric,errors='coerce')\n","    data.dropna(axis=0,inplace=True)\n","    return data"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["def dependent_column(data,column):\n","    \"\"\"\n","    Removes all the Next Day columns.\n","    Removes all the non Growth Rate Columns (GR)\n","    add the predictor column to list of columns.\n","\n","    Parameters\n","    ----------\n","    data : dataframe\n","\n","    column : string\n","        name of the predictor column \n","\n","    Returns\n","    -------\n","    data : dataframe\n","        an updated dataframe after performing all the opertaions.\n","    column : string\n","        name of the predictor column\n","    \"\"\"\n","    cols = [col for col in data.columns if \"next\" not in col.lower() and col.lower().endswith(\"gr\")]\n","    cols.append(column)\n","    data = data[cols]\n","    return (data,column)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["def reshape_data(x_train, x_test, y_train, y_test):\n","    x_train = np.array(x_train)\n","    x_train = np.reshape(x_train, (x_train.shape[0],1, x_train.shape[1]))\n","    x_test = np.array(x_test)\n","    x_test = np.reshape(x_test, (x_test.shape[0],1, x_test.shape[1]))\n","    y_test = np.array(y_test)\n","    y_test = np.reshape(y_test, (y_test.shape[0],1))\n","\n","    return (x_train, x_test, y_train, y_test)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["def swish(x, beta = 1):\n","    return (x * sigmoid(beta * x))"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["def build_lstm(X_train,layers,units = 50):\n","    model = Sequential()\n","    model.add(LSTM(units=units,return_sequences=True,input_shape=(1,X_train.shape[1])))\n","    model.add(Dropout(0.2))\n","    for i in range(layers):\n","        model.add(LSTM(units=units,return_sequences=True))\n","        model.add(Dropout(0.2))\n","    model.add(Dense(units = 1,activation = 'relu'))\n","    return model"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["def keras_model(input_dim,units = 8):\n","    activation='relu'\n","    dropout_rate=0.2\n","    init_mode='uniform'\n","    weight_constraint=0 \n","    optimizer='adam' \n","    lr = 0.01\n","    momemntum=0\n","    \n","    model = Sequential()\n","    model.add(Dense(units = units, input_dim = input_dim, kernel_initializer=init_mode,activation=activation))\n","    model.add(Dropout(dropout_rate)) \n","    model.add(Dense(1, kernel_initializer=init_mode, activation='sigmoid'))\n","    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n","\n","    return model"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["def tuning(model,epochs,batch_size,X_train,Y_train):\n","    param_grid = dict(epochs=epochs, batch_size=batch_size)\n","    grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1,verbose=0)\n","    grid_result = grid.fit(X_train,Y_train) \n","    epoch = grid_result.best_params_['epochs']\n","    batch_size = grid_result.best_params_['batch_size']\n","    \n","    return (epoch,batch_size)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["def create_confusion_matrix(y_pred,y_true):\n","    \n","    cm = confusion_matrix(y_true,y_pred)\n","    accuracy = metrics.accuracy_score(y_true,y_pred)\n","    precision = metrics.precision_score(y_true,y_pred)\n","    recall = metrics.recall_score(y_true,y_pred)\n","    f1_score = metrics.f1_score(y_true,y_pred)\n","    return {\"accuracy\":accuracy,\"precision\":precision,\"recall\":recall,\"f1_score\":f1_score,\"confusion matrix\":cm}"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["combinations = list()\n","def get_combinations(arr):\n","    n = len(arr)\n","    indices = [0 for i in range(n)]\n","    while (1):\n","        res = list()\n","        for i in range(n):\n","            res.append(arr[i][indices[i]])\n","        combinations.append(res)\n","        next = n - 1\n","        while (next >= 0 and\n","              (indices[next] + 1 >= len(arr[next]))):\n","            next-=1\n","        if (next < 0):\n","            return\n","        indices[next] += 1\n","        for i in range(next + 1, n):\n","            indices[i] = 0\n","u = [25,50,100]\n","b = [25,32,64]\n","e = [25,50,100]\n","t = [0.01,0.02,0.03,0.04]\n","\n","arr = [u,b,e,t]\n","get_combinations(arr)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["def recurrent_neural_networks_classification(df,column = \"Next Day Close Price GR\",layers=3,epochs = 5,batch_size = 32,units=50,threshold = 0.01):\n","    defval = {\"batch_size\":batch_size,\"epochs\":epochs,units:\"units\"}\n","    df[\"Target\"] = df[column].apply(lambda x : 1 if x >= threshold else 0)\n","    X = df.drop(columns=[\"Target\",column])\n","    Y = df[\"Target\"]\n","    x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.3,random_state = 0)\n","#     x_train, x_test, y_train, y_test = reshape_data(x_train, x_test, y_train, y_test)\n","    input_dim = x_train.shape[1]\n","    model = KerasClassifier(build_fn = keras_model, batch_size=batch_size, epochs=epochs,input_dim=input_dim) \n","    batch_size = [25,32,64]\n","    epochs = [25,50,100]\n","    \n","    (epochs,batch_size) = tuning(model,epochs,batch_size,x_train,y_train)\n","    \n","    epochs = [epochs-5,epochs+5]\n","    batch_size = [batch_size-5, batch_size+5]\n","\n","    (epochs,batch_size) = tuning(model,epochs,batch_size,x_train,y_train)\n","    \n","    \n","    model_lstm = build_lstm(x_train,layers,units)\n","    \n","    model_lstm.compile(optimizer='adam',loss='mse',metrics=['accuracy'])\n","    \n","    history_lstm = model.fit(x_train,y_train,epochs = epochs,batch_size = batch_size, validation_data = (x_test,y_test),shuffle = False,verbose=0)\n","\n","    y_pred = model.predict(x_test)\n","    y_pred = np.array(y_pred)\n","    y_pred = np.reshape(y_pred, (y_pred.shape[0],1))\n","\n","    rmse = sqrt(metrics.mean_squared_error(y_test, y_pred))\n","    mae = metrics.mean_absolute_error(y_test, y_pred)\n","    mse = metrics.mean_squared_error(y_test, y_pred)\n","    r2 = metrics.r2_score(y_test, y_pred)\n","\n","    myres = create_confusion_matrix(y_pred,y_test)\n","    myres.update({\"root_mean_squared_error\":rmse,\"mean_absolute_error\":mae,\"mean_squared_error\":mse,\"rsquared_adj\":r2})\n","    myres.update({\"threshold\":threshold})\n","    myres.update(defval)\n","    myres.update({\"batch_size_tune\":batch_size,\"epochs_tune\":epochs,units:\"units\"})\n","    print(\"done\")\n","    return myres"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["layers = 3\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(filename)\n","        filepath = os.path.join(dirname, filename)\n","        df = pd.read_csv(filepath)\n","        column = \"Next Day Close Price GR\"\n","        df = pre_process_data(df,60)\n","        (df,column) = dependent_column(df,column)\n","        arguments = list()\n","        for units,batch_size,epochs,threshold in combinations:\n","            data = [df,column,layers,epochs,batch_size,units,threshold]\n","            arguments.append(data)\n","        threads = ThreadPool(4)\n","        result = threads.starmap(recurrent_neural_networks_classification,arguments[:4])\n","        resultdf = pd.DataFrame(result)\n","        resultdf.to_csv(os.path.join(os.getcwd(),str(filename[2:8])+\"_class\"+\".csv\"),index=None)\n","        break"],"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}